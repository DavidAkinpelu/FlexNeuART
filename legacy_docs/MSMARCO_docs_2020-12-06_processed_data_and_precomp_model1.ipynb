{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes & pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This a reproduction notebook that operates on preprocessed data in FlexNeuART JSONL format\n",
    "2. It does not require running GIZA to generate IBM Model 1 (these models are already trained)\n",
    "3. It assumes the user downloaded [this file from our Google Drive](https://drive.google.com/file/d/1p2H-tjdMe69oIJXX0xEIpLLNbHrkO4Xy/view?usp=sharing) and copied it to the source root directory.\n",
    "4. The installation procedure is covered in a [separate notebook](INSTALL_LEGACY.md).\n",
    "5. One should use the following mini-release:\n",
    "```\n",
    "git checkout tags/repr2020-12-06\n",
    "```\n",
    "6. The performance of **your fusion model may vary somewhat** (and be slightly different from what we got here), but we expect the difference to be small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data unpacking/preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download [this file from our Google Drive](https://drive.google.com/file/d/1p2H-tjdMe69oIJXX0xEIpLLNbHrkO4Xy/view?usp=sharing) and copy it to the source root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to the root source directory & unpack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvf msmarco_docs_data_2020-12-06.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data sub-directory: bitext\n",
      "Checking data sub-directory: dev\n",
      "Checking data sub-directory: dev_official\n",
      "Checking data sub-directory: docs\n",
      "Found indexable data file: docs/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: test2019\n",
      "Checking data sub-directory: test2020\n",
      "Checking data sub-directory: train_fusion\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: dev/QuestionFields.jsonl\n",
      "Found query file: dev_official/QuestionFields.jsonl\n",
      "Found query file: test2019/QuestionFields.jsonl\n",
      "Found query file: test2020/QuestionFields.jsonl\n",
      "Found query file: train_fusion/QuestionFields.jsonl\n",
      "getIndexQueryDataInfo return value:  docs AnswerFields.jsonl.gz ,bitext,dev,dev_official,test2019,test2020,train_fusion QuestionFields.jsonl\n",
      "Using the data input files: AnswerFields.jsonl.gz, QuestionFields.jsonl\n",
      "Index dirs: docs\n",
      "Query dirs:  bitext dev dev_official test2019 test2020 train_fusion\n",
      "Queries/questions:\n",
      "bitext 352013\n",
      "dev 5000\n",
      "dev_official 5193\n",
      "test2019 200\n",
      "test2020 200\n",
      "train_fusion 10000\n",
      "Documents/passages/answers:\n",
      "docs 45175731\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_basic_collect_stat.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucene index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/index/create_lucene_index.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward indices (text_raw is not really necessary for this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!field_def=\"title_unlemm:parsedText url_unlemm:parsedText \\\n",
    "            text:parsedText body:parsedText \\\n",
    "            text_bert_tok:parsedText \\\n",
    "            text_raw:raw\"   ;\\\n",
    "scripts/index/create_fwd_index.sh msmarco_doc mapdb \"$field_def\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally warm up the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/warmup_indices.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: BM25 run on the \"official\" development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh   \\\n",
    "   msmarco_doc  \\\n",
    "   exper_desc.lb2020-12-04/bm25_test.json  \\\n",
    "   -test_part dev_official \\\n",
    "   -no_separate_shell   \\\n",
    "   -metric_type RR@100 \\\n",
    "   -test_cand_qty_list 100,1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the end this script should output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================\n",
    "N=100\n",
    "================================================================================\n",
    "# of queries:    5193\n",
    "NDCG@10:        0.313800\n",
    "NDCG@20:        0.339600\n",
    "NDCG@100:       0.372600\n",
    "ERR@20:         0.016410\n",
    "P20:            0.030200\n",
    "MAP:            0.267100\n",
    "MRR:            0.267100\n",
    "Recall:         0.781822\n",
    "GDEVAL NDCG@20: 0.339560\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LAMBDAMART model using train_fusion and test it on dev_official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh   \\\n",
    "   msmarco_doc  \\\n",
    "   exper_desc.lb2020-12-04/best_classic_ir_expand_full_lmart_train.json  \\\n",
    "   -train_part train_fusion \\\n",
    "   -test_part dev_official \\\n",
    "   -no_separate_shell   \\\n",
    "   -metric_type RR@100 \\\n",
    "   -test_cand_qty_list 100,1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the end this script should output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================\n",
    "N=100\n",
    "================================================================================\n",
    "# of queries:    5193\n",
    "NDCG@10:        0.396600\n",
    "NDCG@20:        0.421000\n",
    "NDCG@100:       0.447700\n",
    "ERR@20:         0.020940\n",
    "P20:            0.035600\n",
    "MAP:            0.338900\n",
    "MRR:            0.338900\n",
    "Recall:         0.851916\n",
    "GDEVAL NDCG@20: 0.421030\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of logs, trained models, and TREC-style runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exper.log  letor  rep  trec_runs\r\n"
     ]
    }
   ],
   "source": [
    "!ls collections/msmarco_doc/results/dev_official/feat_exper/best_classic_ir_full_lmart_expand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the trained model to the location specified in the descriptors and test it on TREC NIST 2019 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp collections/msmarco_doc/results/dev_official/feat_exper/best_classic_ir_full_lmart_expand/letor/out_msmarco_doc_train_fusion_20.model collections/msmarco_doc/exper_desc.lb2020-12-04/models/lmart.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh   \\\n",
    "   msmarco_doc  \\\n",
    "   exper_desc.lb2020-12-04/best_classic_ir_expand_full_lmart_test.json  \\\n",
    "   -test_part test2019 \\\n",
    "   -no_separate_shell   \\\n",
    "   -metric_type RR@100 \\\n",
    "   -test_cand_qty_list 100,1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the end the script should output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "================================================================================\n",
    "N=100\n",
    "================================================================================\n",
    "# of queries:    43\n",
    "NDCG@10:        0.589900\n",
    "NDCG@20:        0.561800\n",
    "NDCG@100:       0.544500\n",
    "ERR@20:         0.394260\n",
    "P20:            0.577900\n",
    "MAP:            0.262600\n",
    "MRR:            0.888400\n",
    "Recall:         0.219494\n",
    "GDEVAL NDCG@20: 0.520620\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
