{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation: Tuning BM25 & Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments are described using simple eperimental descriptors, which we will store in the directory `collections/wikipedia_dpr_nq_sample/exper_desc`. The provided tar-ball with data has some key experimental descriptors. However, it does not have descriptors to tune BM25 and the fusion of BM25 with other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to move to the top-level directory ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leo/SourceTreeGit/FlexNeuART.refact2021\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and create a directory to store experiment descriptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p collections/wikipedia_dpr_nq_sample/exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning BM25\n",
    "A tuning procedure simply executes a number of descriptor files\n",
    "with various BM25 parameters. To create descriptors one runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(exper_subdir='tuning', index_field_name='text', outdir='collections/wikipedia_dpr_nq_sample/exper_desc/', query_field_name='text', rel_desc_path='exper_desc')\r\n"
     ]
    }
   ],
   "source": [
    "!scripts/gen_exper_desc/gen_bm25_tune_json_desc.py \\\n",
    "  --index_field_name text \\\n",
    "  --query_field_name text \\\n",
    "  --outdir collections/wikipedia_dpr_nq_sample/exper_desc/ \\\n",
    "  --exper_subdir tuning \\\n",
    "  --rel_desc_path exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 experiments need a dummy one-feature model, which can be created like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p collections/wikipedia_dpr_nq_sample/exper_desc/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: collections/wikipedia_dpr_nq_sample/exper_desc/models/one_feat.model: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cp collections/wikipedia_dpr_nq_sample/exper_desc/models/one_feat.model  collections/wikipedia_dpr_nq_sample/exper_desc/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main experimental descriptor is going to be stored in  `collections/wikipedia_dpr_nq_sample/exper_desc/bm25tune.json`,\n",
    "whereas auxiliary descriptors are stored in `collections/wikipedia_dpr_nq_sample/exper_desc/bm25tune/`\n",
    "\n",
    "Now we can run tuning experiments where we train on `train` and test on `dev1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh \\\n",
    "  wikipedia_dpr_nq_sample \\\n",
    "  exper_desc/bm25tune_text_text.json \\\n",
    "  -test_part dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, experiments are run in the background: In fact, there can be more than one experiment run. However, for debugging purposes, one can run experiments in the foreground by specifying the option -no_separate_shell.\n",
    "\n",
    "Furthermore, the script scripts/exper/run_experiments.sh has a number of parameters, which might be worth tweaking. In particular, for \"shallow\" relevance pools, one can use default number of candidates (which is small). However, for queries with a lot of relevance judgments, it makes sense to slightly increase the number of top candidate entries that are used to obtain a fusion model (parameter -train_cand_qty).\n",
    "\n",
    "Now, let us obtain experimental results and find the best configuration with respect to the Mean Average Precision (MAP), which should be nearly equal to 0.3501:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Including only runs that generated 250 candidate records\n",
      "Best results for metric map:\n",
      "Value: 0.350100\n",
      "Result sub-dir: tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.3\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_exper_results.sh \\\n",
    "  wikipedia_dpr_nq_sample \\\n",
    "  exper_desc/bm25tune_text_text.json \\\n",
    "  bm25tune.tsv \\\n",
    "  -test_part dev \\\n",
    "  -flt_cand_qty 250 \\\n",
    "  -print_best_metr map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning a fusion of IBM Model 1 and BM25\n",
    "\n",
    "IBM Model 1 has quite a few parameters and can benefit from tuning as well.\n",
    "Rather than tuning IBM Model 1 alone, we tune its fusion with the BM25 score for the field\n",
    "`text`. Here we use optimal BM25 coefficients __obtained in the previous experiment__.\n",
    "Model 1 descriptors are going to be created for the field `text_bert_tok`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b=0.3, exper_subdir='tuning', index_field_name='text_bert_tok', k1=0.6, outdir='collections/wikipedia_dpr_nq_sample/exper_desc/', query_field_name='text_bert_tok', rel_desc_path='exper_desc')\r\n"
     ]
    }
   ],
   "source": [
    "!scripts/gen_exper_desc/gen_model1_exper_json_desc.py \\\n",
    "  -k1 0.6 -b 0.3  \\\n",
    "  --exper_subdir tuning \\\n",
    "  --query_field_name text_bert_tok \\\n",
    "  --index_field_name text_bert_tok \\\n",
    "  --outdir collections/wikipedia_dpr_nq_sample/exper_desc/ \\\n",
    "  --rel_desc_path exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run tuning experiments where we train on `train_fusion` and test on `dev` (or `dev_official` if necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh \\\n",
    "  wikipedia_dpr_nq_sample \\\n",
    "  exper_desc/model1tune_text_bert_tok_text_bert_tok.json \\\n",
    "  -test_part dev -train_part train_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the best configuration with respect to MAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Including only runs that generated 250 candidate records\n",
      "Best results for metric map:\n",
      "Value: 0.442200\n",
      "Result sub-dir: tuning/model1tune_text_bert_tok_text_bert_tok/bm25=text+model1=text_bert_tok+lambda=0.3+probSelfTran=0.35\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_exper_results.sh \\\n",
    "  wikipedia_dpr_nq_sample \\\n",
    "  exper_desc/model1tune_text_bert_tok_text_bert_tok.json \\\n",
    "  model1_text_bert_tok_tune.tsv \\\n",
    "  -test_part dev \\\n",
    "  -flt_cand_qty 250 \\\n",
    "  -print_best_metr map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
