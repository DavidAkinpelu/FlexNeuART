{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to move to the top-level directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leo/SourceTreeGit/FlexNeuART.refact2021\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION='wikipedia_dpr_nq_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Java JAR to the class path\n",
    "configure_classpath('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager(f'collections/{COLLECTION}/forward_index',\n",
    "                                                  model1_root_dir=f'collections/{COLLECTION}/derived_data/giza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import QUESTION_FILE_JSON, QREL_FILE, DOCID_FIELD, TEXT_FIELD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, f'collections/{COLLECTION}/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TEXT = \"vein carry blood heart away\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338,\n",
       " [CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       "  CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       "  CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       "  CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       "  CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       "  CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       "  CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       "  CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       "  CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       "  CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       "  CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       "  CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       "  CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       "  CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       "  CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       "  CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       "  CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       "  CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       "  CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       "  CandidateEntry(doc_id='47129', score=13.15163803100586)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a text query\n",
    "query_res = run_text_query(cand_prov, 20, QUERY_TEXT)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338,\n",
       " [CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       "  CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       "  CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       "  CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       "  CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       "  CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       "  CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       "  CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       "  CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       "  CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       "  CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       "  CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       "  CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       "  CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       "  CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       "  CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       "  CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       "  CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       "  CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       "  CandidateEntry(doc_id='47129', score=13.15163803100586)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a generic query interface\n",
    "query_res = run_query(cand_prov, 20, {TEXT_FIELD_NAME : QUERY_TEXT}, default_query_id=FAKE_QUERY_ID)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338,\n",
       " [CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       "  CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       "  CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       "  CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       "  CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       "  CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       "  CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       "  CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       "  CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       "  CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       "  CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       "  CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       "  CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       "  CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       "  CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       "  CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       "  CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       "  CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       "  CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       "  CandidateEntry(doc_id='47129', score=13.15163803100586)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a generic query interface\n",
    "query_res = run_query(cand_prov, 20, {DOCID_FIELD: FAKE_QUERY_ID, TEXT_FIELD_NAME : QUERY_TEXT})\n",
    "query_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward index demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's play with a raw index that keeps ony unparsed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_indx = get_forward_index(resource_manager, 'text_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'textRaw'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index type\n",
    "raw_indx.indx_fld_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vein \"Vein Veins are blood vessels that carry blood toward the heart. Most veins carry deoxygenated blood from the tissues back to the heart; exceptions are the pulmonary and umbilical veins, both of which carry oxygenated blood to the heart. In contrast to veins, arteries carry blood away from the heart. Veins are less muscular than arteries and are often closer to the skin. There are valves in most veins to prevent backflow. Veins are present throughout the body as tubes that carry blood back to the heart. Veins are classified in a number of ways, including superficial vs. deep, pulmonary\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_indx.get_doc_text_raw('639661')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A parsed index has more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_indx = get_forward_index(resource_manager, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parsedText'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index type\n",
    "parsed_indx.indx_fld_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocEntryParsed(word_ids=[75, 144, 210, 246, 506, 587, 589, 591, 594, 867, 1268, 1282, 2311, 2516, 3125, 3352, 4121, 5121, 7795, 8410, 8455, 12461, 14717, 14722, 14724, 23655, 23669, 27261, 59794, 102036], word_qtys=[1, 1, 5, 1, 5, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 9, 6, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1], word_id_seq=[7795, 7795, 102036, 8410, 5121, 506, 8410, 210, 7795, 506, 23655, 8410, 587, 2311, 210, 14724, 23669, 7795, 506, 14717, 8410, 210, 4121, 7795, 8455, 506, 8410, 3125, 210, 7795, 27261, 8455, 246, 589, 14722, 7795, 1282, 59794, 7795, 1268, 75, 2516, 506, 8410, 2311, 210, 7795, 3352, 144, 867, 591, 12461, 594, 14724], doc_len=54)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_indx.get_doc_parsed('639661')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('body', WordEntry(word_id=75, word_freq=17735))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract the first document word and its info\n",
    "parsed_indx.get_word_by_id(75), parsed_indx.get_word_entry_by_id(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.ranker import *\n",
    "from scripts.py_flexneuart.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE_NAME=f'collections/{COLLECTION}/exper_desc.best/models/bm25_model1.model'\n",
    "FEAT_EXTR_FILE_NAME=f'collections/{COLLECTION}/exper_desc.best/extractors/bm25=text+model1=text_bert_tok+lambda=0.3+probSelfTran=0.35.json'\n",
    "QUERY_FILE_NAME=f'collections/{COLLECTION}/input_data/dev/{QUESTION_FILE_JSON}'\n",
    "QREL_FILE_NAME=f'collections/{COLLECTION}/input_data/dev/{QREL_FILE}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we generate a list of candidates for merely one query (using the candidate provider) and re-rank them using the Java-layer re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_ranker = JavaQueryRanker(resource_manager, \n",
    "                              feat_extr_file_name=FEAT_EXTR_FILE_NAME, \n",
    "                              model_file_name=MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('639661', 0.4589444396983704),\n",
       " ('1776205', 0.4341061334562677),\n",
       " ('472789', 0.4324617381414335),\n",
       " ('8448903', 0.4124776432310974),\n",
       " ('8448902', 0.41143788988374125),\n",
       " ('35722', 0.39951390916561724),\n",
       " ('639669', 0.38760818984443224),\n",
       " ('3936360', 0.3864522671342978),\n",
       " ('1450640', 0.38388484121055044),\n",
       " ('588394', 0.38289955583934543),\n",
       " ('639670', 0.3823782759630887),\n",
       " ('639663', 0.3775039059463895),\n",
       " ('47133', 0.3731257557936975),\n",
       " ('1302853', 0.36679545440286726),\n",
       " ('639690', 0.3653150559189846),\n",
       " ('639671', 0.36361852471115813),\n",
       " ('1786523', 0.36268165971062455),\n",
       " ('2992576', 0.353630291595394),\n",
       " ('5622935', 0.3518175514979561),\n",
       " ('47129', 0.34765838000119853)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              TEXT_FIELD_NAME : QUERY_TEXT}\n",
    "java_ranker.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There's a function (used only for evaluation) to score candidates without sorting them scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'639661': 0.4589444396983704,\n",
       " '472789': 0.4324617381414335,\n",
       " '1776205': 0.4341061334562677,\n",
       " '639669': 0.38760818984443224,\n",
       " '8448903': 0.4124776432310974,\n",
       " '8448902': 0.41143788988374125,\n",
       " '639670': 0.3823782759630887,\n",
       " '639663': 0.3775039059463895,\n",
       " '35722': 0.39951390916561724,\n",
       " '1302853': 0.36679545440286726,\n",
       " '639671': 0.36361852471115813,\n",
       " '1786523': 0.36268165971062455,\n",
       " '588394': 0.38289955583934543,\n",
       " '639690': 0.3653150559189846,\n",
       " '1450640': 0.38388484121055044,\n",
       " '3936360': 0.3864522671342978,\n",
       " '5622935': 0.3518175514979561,\n",
       " '2992576': 0.353630291595394,\n",
       " '47133': 0.3731257557936975,\n",
       " '47129': 0.34765838000119853}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_ranker.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we re-rank the list of candidate using a BERT re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ranking on CPU, which can be fairly slow\n",
    "neural_ranker = PythonNNQueryRanker(resource_manager, \n",
    "                         query_field_name='text_raw', max_query_len=64,\n",
    "                         index_field_name='text_raw', max_doc_len = 512 - 32 - 3,\n",
    "                         device_name='cuda', batch_size=25, \n",
    "                         model_file_name=f'collections/{COLLECTION}/derived_data/ir_models/vanilla_bert/model.best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('639661', 3.1647984981536865),\n",
       " ('639690', 2.259718656539917),\n",
       " ('472789', 2.1923577785491943),\n",
       " ('639670', 2.032242774963379),\n",
       " ('35722', 1.9418951272964478),\n",
       " ('1786523', 1.8832405805587769),\n",
       " ('639671', 1.755630373954773),\n",
       " ('639669', 1.7364437580108643),\n",
       " ('639663', 1.7072409391403198),\n",
       " ('1776205', 1.663066029548645),\n",
       " ('8448903', 1.4759409427642822),\n",
       " ('3936360', 1.3319076299667358),\n",
       " ('588394', 1.2384809255599976),\n",
       " ('1450640', 1.1465526819229126),\n",
       " ('8448902', 1.131631851196289),\n",
       " ('1302853', 0.8631684184074402),\n",
       " ('47129', 0.8423947095870972),\n",
       " ('5622935', 0.798784613609314),\n",
       " ('47133', 0.6458267569541931),\n",
       " ('2992576', 0.380513995885849)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              'text_raw' : QUERY_TEXT}\n",
    "neural_ranker.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'639661': 3.1647984981536865,\n",
       " '472789': 2.1923577785491943,\n",
       " '1776205': 1.663066029548645,\n",
       " '639669': 1.7364437580108643,\n",
       " '8448903': 1.4759409427642822,\n",
       " '8448902': 1.131631851196289,\n",
       " '639670': 2.032242774963379,\n",
       " '639663': 1.7072409391403198,\n",
       " '35722': 1.9418951272964478,\n",
       " '1302853': 0.8631684184074402,\n",
       " '639671': 1.755630373954773,\n",
       " '1786523': 1.8832405805587769,\n",
       " '588394': 1.2384809255599976,\n",
       " '639690': 2.259718656539917,\n",
       " '1450640': 1.1465526819229126,\n",
       " '3936360': 1.3319076299667358,\n",
       " '5622935': 0.798784613609314,\n",
       " '2992576': 0.380513995885849,\n",
       " '47133': 0.6458267569541931,\n",
       " '47129': 0.8423947095870972}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              'text_raw' : QUERY_TEXT}\n",
    "neural_ranker.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       " CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       " CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       " CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       " CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       " CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       " CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       " CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       " CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       " CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       " CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       " CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       " CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       " CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       " CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       " CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       " CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       " CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       " CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       " CandidateEntry(doc_id='47129', score=13.15163803100586)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_res[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A comprehensive example where we evaluate **all** queries from `dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_convert.convert_common import *\n",
    "all_queries = read_queries(QUERY_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DOCNO': 'dev_0',\n",
       "  'text': 'vein carry blood heart away',\n",
       "  'text_unlemm': 'veins carry blood heart away',\n",
       "  'text_raw': 'do veins carry blood to the heart or away',\n",
       "  'answer_list': ['to'],\n",
       "  'text_bert_tok': 'do veins carry blood to the heart or away'},\n",
       " {'DOCNO': 'dev_1',\n",
       "  'text': 'sister king country',\n",
       "  'text_unlemm': 'sister king country',\n",
       "  'text_raw': 'who is the sister of for king and country',\n",
       "  'answer_list': ['Rebecca St. James'],\n",
       "  'text_bert_tok': 'who is the sister of for king and country'},\n",
       " {'DOCNO': 'dev_2',\n",
       "  'text': 'develop periodic table 8 column',\n",
       "  'text_unlemm': 'developed periodic table 8 columns',\n",
       "  'text_raw': 'who developed the first periodic table with 8 columns',\n",
       "  'answer_list': ['Dmitri Mendeleev'],\n",
       "  'text_bert_tok': 'who developed the first periodic table with 8 columns'},\n",
       " {'DOCNO': 'dev_3',\n",
       "  'text': 'season 14 grey anatomy come',\n",
       "  'text_unlemm': 'season 14 grey anatomy come',\n",
       "  'text_raw': \"when does season 14 of grey 's anatomy come out\",\n",
       "  'answer_list': ['September 28 , 2017'],\n",
       "  'text_bert_tok': \"when does season 14 of grey ' s anatomy come out\"},\n",
       " {'DOCNO': 'dev_4',\n",
       "  'text': 'big statue jesus locate',\n",
       "  'text_unlemm': 'big statue jesus located',\n",
       "  'text_raw': 'where is the big statue of jesus located',\n",
       "  'answer_list': ['Rio de Janeiro , Brazil'],\n",
       "  'text_bert_tok': 'where is the big statue of jesus located'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query sample\n",
    "all_queries[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries have one extra field that cannot be \"digested\" by the ranking API and we need to delete it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:00<00:00, 563114.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for query_dict in tqdm(all_queries):\n",
    "    # Delete this field, it cannot be used by ranker\n",
    "    del query_dict['answer_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 75.58it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.46346817019607056\n",
      "0.4921404695852165\n",
      "0.3837114516067106\n",
      "0.5694028192771883\n",
      "===========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:09<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.5580276779203649\n",
      "0.5702523422094312\n",
      "0.46759618461255126\n",
      "0.6777521001099326\n",
      "===========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.common_eval import *\n",
    "from scripts.utils import sync_out_streams\n",
    "from tqdm import tqdm\n",
    "\n",
    "TOP_K=50\n",
    "MAX_QUERIES_QTY=500\n",
    "qrels=read_qrels_dict(QREL_FILE_NAME)\n",
    "\n",
    "for ranker in [java_ranker, neural_ranker]:\n",
    "    run_dict = {}\n",
    "    with tqdm(all_queries[0:MAX_QUERIES_QTY]) as pbar:\n",
    "        for query_dict in pbar:\n",
    "            qid = query_dict[DOCID_FIELD]\n",
    "            query_res = run_query(cand_prov, TOP_K, query_dict)\n",
    "            rank_res = ranker.score_candidates(query_res[1], query_dict)\n",
    "            run_dict[qid] = rank_res\n",
    "    tqdm.write('\\n')\n",
    "        \n",
    "    # Let us compute various metrics using our Python code. \n",
    "    # Note that results should generally match results obtained using `scripts/exper/run_experiments.sh`\n",
    "    for eval_obj in [NormalizedDiscountedCumulativeGain(10), \\\n",
    "                 NormalizedDiscountedCumulativeGain(20), \\\n",
    "                 MeanAveragePrecision(), \\\n",
    "                 MeanReciprocalRank()]:\n",
    "        tqdm.write(str(eval_run(rerank_run=run_dict, metric_func=eval_obj, qrels_dict=qrels)))\n",
    "    \n",
    "    tqdm.write('==========================='+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionally we can save the run to be later evaluated using external evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_run_dict(run_dict, 'run.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_0 Q0 639661 1 3.0764644145965576 fake_run\r\n",
      "dev_0 Q0 639690 2 2.25703763961792 fake_run\r\n",
      "dev_0 Q0 472789 3 1.9882888793945312 fake_run\r\n",
      "dev_0 Q0 639670 4 1.88827383518219 fake_run\r\n",
      "dev_0 Q0 35722 5 1.7989380359649658 fake_run\r\n",
      "dev_0 Q0 8448903 6 1.6787585020065308 fake_run\r\n",
      "dev_0 Q0 588392 7 1.66169273853302 fake_run\r\n",
      "dev_0 Q0 8448902 8 1.6055868864059448 fake_run\r\n",
      "dev_0 Q0 1776205 9 1.5409656763076782 fake_run\r\n",
      "dev_0 Q0 639663 10 1.4181830883026123 fake_run\r\n"
     ]
    }
   ],
   "source": [
    "!head run.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
