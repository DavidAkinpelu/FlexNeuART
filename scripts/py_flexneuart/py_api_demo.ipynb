{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FlexNeuART'...\n",
      "remote: Enumerating objects: 289, done.\u001b[K\n",
      "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
      "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
      "remote: Total 14643 (delta 129), reused 193 (delta 66), pack-reused 14354\u001b[K\n",
      "Receiving objects: 100% (14643/14643), 31.47 MiB | 31.97 MiB/s, done.\n",
      "Resolving deltas: 100% (8994/8994), done.\n"
     ]
    }
   ],
   "source": [
    "# Building sources\n",
    "!git clone git@github.com:oaqa/FlexNeuART.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leo/Downloads/test/FlexNeuART\n"
     ]
    }
   ],
   "source": [
    "cd FlexNeuART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Python packages to install:\n",
      "lxml pytools torch 1.4 torchtext 0.6.0 numpy bs4 thrift 0.13.0 spacy 2.2.3 pyjnius\n",
      "Installing package lxml -> \n",
      "Requirement already satisfied: lxml in /Users/leo/anaconda3/lib/python3.8/site-packages (4.6.1)\n",
      "Installing package pytools -> \n",
      "Requirement already satisfied: pytools in /Users/leo/anaconda3/lib/python3.8/site-packages (2021.1)\n",
      "Requirement already satisfied: numpy>=1.6.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from pytools) (1.18.2)\n",
      "Requirement already satisfied: decorator>=3.2.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from pytools) (4.4.2)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from pytools) (1.4.4)\n",
      "Installing package torch -> 1.4\n",
      "Requirement already satisfied: torch==1.4 in /Users/leo/anaconda3/lib/python3.8/site-packages (1.4.0)\n",
      "Installing package torchtext -> 0.6.0\n",
      "Requirement already satisfied: torchtext==0.6.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: numpy in /Users/leo/anaconda3/lib/python3.8/site-packages (from torchtext==0.6.0) (1.18.2)\n",
      "Requirement already satisfied: six in /Users/leo/anaconda3/lib/python3.8/site-packages (from torchtext==0.6.0) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /Users/leo/anaconda3/lib/python3.8/site-packages (from torchtext==0.6.0) (4.50.2)\n",
      "Requirement already satisfied: requests in /Users/leo/anaconda3/lib/python3.8/site-packages (from torchtext==0.6.0) (2.24.0)\n",
      "Requirement already satisfied: torch in /Users/leo/anaconda3/lib/python3.8/site-packages (from torchtext==0.6.0) (1.4.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/leo/anaconda3/lib/python3.8/site-packages (from torchtext==0.6.0) (0.1.95)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (2.10)\n",
      "Installing package numpy -> \n",
      "Requirement already satisfied: numpy in /Users/leo/anaconda3/lib/python3.8/site-packages (1.18.2)\n",
      "Installing package bs4 -> \n",
      "Requirement already satisfied: bs4 in /Users/leo/anaconda3/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/leo/anaconda3/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Users/leo/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Installing package thrift -> 0.13.0\n",
      "Requirement already satisfied: thrift==0.13.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: six>=1.7.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from thrift==0.13.0) (1.15.0)\n",
      "Installing package spacy -> 2.2.3\n",
      "Requirement already satisfied: spacy==2.2.3 in /Users/leo/anaconda3/lib/python3.8/site-packages (2.2.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (3.0.5)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (7.3.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (2.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (1.18.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy==2.2.3) (2.24.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.50.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.10)\n",
      "Installing package pyjnius -> \n",
      "Collecting pyjnius\n",
      "  Downloading pyjnius-1.3.0-cp38-cp38-macosx_10_13_x86_64.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cython in /Users/leo/anaconda3/lib/python3.8/site-packages (from pyjnius) (0.29.21)\n",
      "Requirement already satisfied: six>=1.7.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from pyjnius) (1.15.0)\n",
      "Installing collected packages: pyjnius\n",
      "Successfully installed pyjnius-1.3.0\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /Users/leo/anaconda3/lib/python3.8/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.24.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/leo/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/leo/anaconda3/lib/python3.8/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.50.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Cloning into 'pytorch-pretrained-BERT-mod'...\n",
      "remote: Enumerating objects: 85, done.\u001b[K\n",
      "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
      "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
      "remote: Total 85 (delta 27), reused 79 (delta 21), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (85/85), 293.34 KiB | 3.22 MiB/s, done.\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating pytorch_pretrained_bert.egg-info\n",
      "writing pytorch_pretrained_bert.egg-info/PKG-INFO\n",
      "writing dependency_links to pytorch_pretrained_bert.egg-info/dependency_links.txt\n",
      "writing entry points to pytorch_pretrained_bert.egg-info/entry_points.txt\n",
      "writing requirements to pytorch_pretrained_bert.egg-info/requires.txt\n",
      "writing top-level names to pytorch_pretrained_bert.egg-info/top_level.txt\n",
      "writing manifest file 'pytorch_pretrained_bert.egg-info/SOURCES.txt'\n",
      "reading manifest file 'pytorch_pretrained_bert.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'pytorch_pretrained_bert.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.macosx-10.9-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/modeling_transfo_xl.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/convert_openai_checkpoint_to_pytorch.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/tokenization_gpt2.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/convert_transfo_xl_checkpoint_to_pytorch.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/tokenization_openai.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/modeling_gpt2.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/optimization.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/__init__.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/tokenization.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/optimization_openai.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/modeling_transfo_xl_utilities.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/modeling_openai.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/convert_gpt2_checkpoint_to_pytorch.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/file_utils.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/tokenization_transfo_xl.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/modeling.py -> build/lib/pytorch_pretrained_bert\n",
      "copying pytorch_pretrained_bert/__main__.py -> build/lib/pytorch_pretrained_bert\n",
      "creating build/bdist.macosx-10.9-x86_64\n",
      "creating build/bdist.macosx-10.9-x86_64/egg\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/modeling_transfo_xl.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/convert_openai_checkpoint_to_pytorch.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/tokenization_gpt2.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/convert_transfo_xl_checkpoint_to_pytorch.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/tokenization_openai.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/modeling_gpt2.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/optimization.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/__init__.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/tokenization.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/optimization_openai.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/modeling_transfo_xl_utilities.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/modeling_openai.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/convert_gpt2_checkpoint_to_pytorch.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/file_utils.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/tokenization_transfo_xl.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/modeling.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "copying build/lib/pytorch_pretrained_bert/__main__.py -> build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/modeling_transfo_xl.py to modeling_transfo_xl.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/convert_openai_checkpoint_to_pytorch.py to convert_openai_checkpoint_to_pytorch.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/tokenization_gpt2.py to tokenization_gpt2.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/convert_tf_checkpoint_to_pytorch.py to convert_tf_checkpoint_to_pytorch.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/convert_transfo_xl_checkpoint_to_pytorch.py to convert_transfo_xl_checkpoint_to_pytorch.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/tokenization_openai.py to tokenization_openai.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/modeling_gpt2.py to modeling_gpt2.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/optimization.py to optimization.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/tokenization.py to tokenization.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/optimization_openai.py to optimization_openai.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/modeling_transfo_xl_utilities.py to modeling_transfo_xl_utilities.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/modeling_openai.py to modeling_openai.cpython-38.pyc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/convert_gpt2_checkpoint_to_pytorch.py to convert_gpt2_checkpoint_to_pytorch.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/file_utils.py to file_utils.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/tokenization_transfo_xl.py to tokenization_transfo_xl.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/modeling.py to modeling.cpython-38.pyc\n",
      "byte-compiling build/bdist.macosx-10.9-x86_64/egg/pytorch_pretrained_bert/__main__.py to __main__.cpython-38.pyc\n",
      "creating build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying pytorch_pretrained_bert.egg-info/PKG-INFO -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying pytorch_pretrained_bert.egg-info/SOURCES.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying pytorch_pretrained_bert.egg-info/dependency_links.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying pytorch_pretrained_bert.egg-info/entry_points.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying pytorch_pretrained_bert.egg-info/requires.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "copying pytorch_pretrained_bert.egg-info/top_level.txt -> build/bdist.macosx-10.9-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/pytorch_pretrained_bert-0.6.2-py3.8.egg' and adding 'build/bdist.macosx-10.9-x86_64/egg' to it\n",
      "removing 'build/bdist.macosx-10.9-x86_64/egg' (and everything under it)\n",
      "Processing pytorch_pretrained_bert-0.6.2-py3.8.egg\n",
      "Removing /Users/leo/anaconda3/lib/python3.8/site-packages/pytorch_pretrained_bert-0.6.2-py3.8.egg\n",
      "Copying pytorch_pretrained_bert-0.6.2-py3.8.egg to /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "pytorch-pretrained-bert 0.6.2 is already the active version in easy-install.pth\n",
      "Installing pytorch_pretrained_bert script to /Users/leo/anaconda3/bin\n",
      "\n",
      "Installed /Users/leo/anaconda3/lib/python3.8/site-packages/pytorch_pretrained_bert-0.6.2-py3.8.egg\n",
      "Processing dependencies for pytorch-pretrained-bert==0.6.2\n",
      "Searching for regex==2020.10.15\n",
      "Best match: regex 2020.10.15\n",
      "Adding regex 2020.10.15 to easy-install.pth file\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for tqdm==4.50.2\n",
      "Best match: tqdm 4.50.2\n",
      "Adding tqdm 4.50.2 to easy-install.pth file\n",
      "Installing tqdm script to /Users/leo/anaconda3/bin\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for requests==2.24.0\n",
      "Best match: requests 2.24.0\n",
      "Adding requests 2.24.0 to easy-install.pth file\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for boto3==1.17.1\n",
      "Best match: boto3 1.17.1\n",
      "Processing boto3-1.17.1-py3.8.egg\n",
      "boto3 1.17.1 is already the active version in easy-install.pth\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages/boto3-1.17.1-py3.8.egg\n",
      "Searching for numpy==1.18.2\n",
      "Best match: numpy 1.18.2\n",
      "Adding numpy 1.18.2 to easy-install.pth file\n",
      "Installing f2py script to /Users/leo/anaconda3/bin\n",
      "Installing f2py3 script to /Users/leo/anaconda3/bin\n",
      "Installing f2py3.8 script to /Users/leo/anaconda3/bin\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for torch==1.4.0\n",
      "Best match: torch 1.4.0\n",
      "Adding torch 1.4.0 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /Users/leo/anaconda3/bin\n",
      "Installing convert-onnx-to-caffe2 script to /Users/leo/anaconda3/bin\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for chardet==3.0.4\n",
      "Best match: chardet 3.0.4\n",
      "Adding chardet 3.0.4 to easy-install.pth file\n",
      "Installing chardetect script to /Users/leo/anaconda3/bin\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for idna==2.10\n",
      "Best match: idna 2.10\n",
      "Adding idna 2.10 to easy-install.pth file\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for urllib3==1.25.11\n",
      "Best match: urllib3 1.25.11\n",
      "Adding urllib3 1.25.11 to easy-install.pth file\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for certifi==2020.12.5\n",
      "Best match: certifi 2020.12.5\n",
      "Processing certifi-2020.12.5-py3.8.egg\n",
      "certifi 2020.12.5 is already the active version in easy-install.pth\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages/certifi-2020.12.5-py3.8.egg\n",
      "Searching for s3transfer==0.3.4\n",
      "Best match: s3transfer 0.3.4\n",
      "Processing s3transfer-0.3.4-py3.8.egg\n",
      "s3transfer 0.3.4 is already the active version in easy-install.pth\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages/s3transfer-0.3.4-py3.8.egg\n",
      "Searching for jmespath==0.10.0\n",
      "Best match: jmespath 0.10.0\n",
      "Processing jmespath-0.10.0-py3.8.egg\n",
      "jmespath 0.10.0 is already the active version in easy-install.pth\n",
      "Installing jp.py script to /Users/leo/anaconda3/bin\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages/jmespath-0.10.0-py3.8.egg\n",
      "Searching for botocore==1.20.1\n",
      "Best match: botocore 1.20.1\n",
      "Processing botocore-1.20.1-py3.8.egg\n",
      "botocore 1.20.1 is already the active version in easy-install.pth\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages/botocore-1.20.1-py3.8.egg\n",
      "Searching for python-dateutil==2.8.1\n",
      "Best match: python-dateutil 2.8.1\n",
      "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Searching for six==1.15.0\n",
      "Best match: six 1.15.0\n",
      "Adding six 1.15.0 to easy-install.pth file\n",
      "\n",
      "Using /Users/leo/anaconda3/lib/python3.8/site-packages\n",
      "Finished processing dependencies for pytorch-pretrained-bert==0.6.2\n",
      "Cloning into 'mgiza'...\n",
      "remote: Enumerating objects: 1042, done.\u001b[K\n",
      "remote: Total 1042 (delta 0), reused 0 (delta 0), pack-reused 1042\u001b[K\n",
      "Receiving objects: 100% (1042/1042), 1.29 MiB | 12.37 MiB/s, done.\n",
      "Resolving deltas: 100% (644/644), done.\n",
      "-- The C compiler identification is AppleClang 10.0.1.10010046\n",
      "-- The CXX compiler identification is AppleClang 10.0.1.10010046\n",
      "-- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc\n",
      "-- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++\n",
      "-- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- You have not set the install dir, default to './inst', if\n",
      "    you want to set it, use cmake -DCMAKE_INSTALL_PREFIX to do so\n",
      "-- Performing Test TR1_SHARED_PTR_USE_TR1_MEMORY\n",
      "-- Performing Test TR1_SHARED_PTR_USE_TR1_MEMORY - Failed\n",
      "-- Performing Test TR1_SHARED_PTR_USE_MEMORY\n",
      "-- Performing Test TR1_SHARED_PTR_USE_MEMORY - Failed\n",
      "-- Performing Test TR1_UNORDERED_MAP_USE_TR1_UNORDERED_MAP\n",
      "-- Performing Test TR1_UNORDERED_MAP_USE_TR1_UNORDERED_MAP - Failed\n",
      "-- Performing Test TR1_UNORDERED_MAP_USE_UNORDERED_MAP\n",
      "-- Performing Test TR1_UNORDERED_MAP_USE_UNORDERED_MAP - Failed\n",
      "-- Found Boost: /usr/local/lib/cmake/Boost-1.72.0/BoostConfig.cmake (found suitable version \"1.72.0\", minimum required is \"1.41\") found components: thread system \n",
      "Boost found\n",
      "-- Boost_INCLUDE_DIR    : /usr/local/include\n",
      "-- Found Threads: TRUE  \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp\n",
      "\u001b[35m\u001b[1mScanning dependencies of target snt2plain\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target plain2snt\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target symal\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target mgiza_lib\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/plain2snt.dir/plain2snt.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/symal.dir/symal.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/snt2plain.dir/snt2plain.cpp.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/alignment.cpp.o\u001b[0m\n",
      "[  7%] \u001b[32m\u001b[1mLinking CXX executable ../bin/snt2plain\u001b[0m\n",
      "[  7%] Built target snt2plain\n",
      "[  8%] \u001b[32mBuilding C object src/CMakeFiles/symal.dir/cmd.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/AlignTables.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32m\u001b[1mLinking CXX executable ../bin/plain2snt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target snt2coocrmp\u001b[0m\n",
      "[ 13%] \u001b[32m\u001b[1mLinking CXX executable ../bin/symal\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/snt2coocrmp.dir/snt2cooc-reduce-mem-preprocess.cpp.o\u001b[0m\n",
      "[ 14%] Built target plain2snt\n",
      "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/ATables.cpp.o\u001b[0m\n",
      "[ 16%] Built target symal\n",
      "[ 17%] \u001b[32mBuilding C object src/CMakeFiles/mgiza_lib.dir/cmd.c.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target snt2cooc\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/snt2cooc.dir/snt2cooc.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/collCounts.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32m\u001b[1mLinking CXX executable ../bin/snt2coocrmp\u001b[0m\n",
      "[ 22%] Built target snt2coocrmp\n",
      "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/Dictionary.cpp.o\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target mkcls\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/collCounts.cpp:28:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/collCounts.cpp:30:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m[ 25%] \u001b[32m\u001b[1mLinking CXX executable ../bin/snt2cooc\u001b[0m\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/collCounts.cpp:129:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "      } else {\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0m[ 26%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/GDAOptimization.cpp.o\u001b[0m\n",
      "[ 26%] Built target snt2cooc\n",
      "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/ForwardBackward.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/general.cpp.o\u001b[0m\n",
      "3 warnings generated.\n",
      "[ 30%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/HCOptimization.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/ForwardBackward.cpp:27:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m[ 32%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/getSentence.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/hmm.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/IterOptimization.cpp.o\u001b[0m\n",
      "1 warning generated.\n",
      "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/HMMTables.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/KategProblem.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.cpp:23:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.cpp:309:13: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          } else {\n",
      "\u001b[0;1;32m            ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.cpp:23:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m1 warning generated.\n",
      "[ 39%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/KategProblemKBC.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/logprob.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/KategProblemTest.cpp.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/KategProblemWBC.cpp.o\u001b[0m\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/mkcls/KategProblemTest.cpp:61:7: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "      else\n",
      "\u001b[0;1;32m      ^\n",
      "\u001b[0m2 warnings generated.\n",
      "[ 47%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/mkcls.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model1.cpp.o\u001b[0m\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/mkcls/mkcls.cpp:131:27: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      illegal character encoding in string literal [-Winvalid-source-encoding]\u001b[0m\n",
      "       \" Franz Josef Och: \u001b[0m\u001b[7m<BB>\u001b[0mMaximum-Likelihood-Sch\u001b[0m\u001b[7m<E4>\u001b[0mtzung von Wortka...\n",
      "\u001b[0;1;32m                          ^~~~                      ~~~~\n",
      "\u001b[0m\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/mkcls/mkcls.cpp:132:67: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      illegal character encoding in string literal [-Winvalid-source-encoding]\u001b[0m\n",
      "  ...Optimierung?Studienarbeit, Universit\u001b[0m\u001b[7m<E4>\u001b[0mt Erlangen-N\u001b[0m\u001b[7m<FC>\u001b[0mrnberg,\\n\"\n",
      "\u001b[0;1;32m                                         ^~~~            ~~~~\n",
      "\u001b[0m2 warnings generated.\n",
      "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model2.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model2to3.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model2to3.cpp:22:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:51:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model2to3.cpp:22:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:55:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m[ 51%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/MYOptimization.cpp.o\u001b[0m\n",
      "1 warning generated.\n",
      "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model345-peg.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/Optimization.cpp.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model3.cpp.o\u001b[0m\n",
      "2 warnings generated.\n",
      "[ 57%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/Problem.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model3_viterbi.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model345-peg.cpp:23:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:51:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m[ 60%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/ProblemTest.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model345-peg.cpp:23:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:55:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.cpp:22:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:51:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.cpp:22:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:55:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.cpp:735:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      'TRAIN_ARGS' macro redefined [-Wmacro-redefined]\u001b[0m\n",
      "#define TRAIN_ARGS perp,      trainViterbiPerp, sHandler1,    true, alig...\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0m\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.cpp:481:9: \u001b[0m\u001b[0;1;30mnote: \u001b[0m\n",
      "      previous definition is here\u001b[0m\n",
      "#define TRAIN_ARGS perp,      trainViterbiPerp, sHandler1,    dump_files...\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0m2 warnings generated.\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3_viterbi.cpp:22:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:51:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m[ 61%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/RRTOptimization.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3_viterbi.cpp:22:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:55:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/model3_viterbi_with_tricks.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/SAOptimization.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3_viterbi_with_tricks.cpp:23:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:51:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m2 warnings generated.\n",
      "[ 66%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/StatVar.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3_viterbi_with_tricks.cpp:23:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:55:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3_viterbi_with_tricks.cpp:839:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/collCounts.cpp:129:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "      } else {\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0m[ 67%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/MoveSwapMatrix.cpp.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object src/mkcls/CMakeFiles/mkcls.dir/TAOptimization.cpp.o\u001b[0m\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/MoveSwapMatrix.cpp:44:7: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "      else\n",
      "\u001b[0;1;32m      ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/MoveSwapMatrix.cpp:207:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_model5.h:32:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/MoveSwapMatrix.cpp:208:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0m[ 70%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/mkcls\u001b[0m\n",
      "[ 70%] Built target mkcls\n",
      "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/myassert.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/NTables.cpp.o\u001b[0m\n",
      "3 warnings generated.\n",
      "3 warnings generated.\n",
      "[ 75%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/Parameter.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/parse.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/Perplexity.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/reports.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/parse.cpp:32:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/SetArray.cpp.o\u001b[0m\n",
      "1 warning generated.\n",
      "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/transpair_model3.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/transpair_model4.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/transpair_model5.cpp.o\u001b[0m\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_model4.cpp:135:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "        } else {\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_model4.cpp:161:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "      } else {\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0m[ 86%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/TTables.cpp.o\u001b[0m\n",
      "2 warnings generated.\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_model5.cpp:23:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_model5.h:32:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m[ 88%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/utility.cpp.o\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza_lib.dir/vocab.cpp.o\u001b[0m\n",
      "1 warning generated.\n",
      "3 warnings generated.\n",
      "[ 91%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libmgiza.a\u001b[0m\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: ../lib/libmgiza.a(collCounts.cpp.o) has no symbols\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: ../lib/libmgiza.a(HMMTables.cpp.o) has no symbols\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: ../lib/libmgiza.a(SetArray.cpp.o) has no symbols\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: ../lib/libmgiza.a(collCounts.cpp.o) has no symbols\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: ../lib/libmgiza.a(HMMTables.cpp.o) has no symbols\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: ../lib/libmgiza.a(SetArray.cpp.o) has no symbols\n",
      "[ 91%] Built target mgiza_lib\n",
      "\u001b[35m\u001b[1mScanning dependencies of target hmmnorm\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target d4norm\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target mgiza\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding CXX object src/CMakeFiles/d4norm.dir/d4norm.cxx.o\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding CXX object src/CMakeFiles/hmmnorm.dir/hmmnorm.cxx.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding CXX object src/CMakeFiles/mgiza.dir/main.cpp.o\u001b[0m\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmmnorm.cxx:6:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/d4norm.cxx:6:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/main.cpp:28:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:51:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/transpair_modelhmm.h:35:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/hmm.h:53:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/HMMTables.h:185:15: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "            } else {\n",
      "\u001b[0;1;32m              ^\n",
      "\u001b[0mIn file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/main.cpp:28:\n",
      "In file included from /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/model3.h:55:\n",
      "\u001b[1m/Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/src/D5Tables.h:191:11: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1m\n",
      "      add explicit braces to avoid dangling else [-Wdangling-else]\u001b[0m\n",
      "          else\n",
      "\u001b[0;1;32m          ^\n",
      "\u001b[0m1 warning generated.\n",
      "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../bin/hmmnorm\u001b[0m\n",
      "1 warning generated.\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../bin/d4norm\u001b[0m\n",
      "[ 98%] Built target hmmnorm\n",
      "[ 98%] Built target d4norm\n",
      "2 warnings generated.\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable ../bin/mgiza\u001b[0m\n",
      "[100%] Built target mgiza\n",
      "[ 48%] Built target mgiza_lib\n",
      "[ 51%] Built target d4norm\n",
      "[ 54%] Built target hmmnorm\n",
      "[ 57%] Built target mgiza\n",
      "[ 61%] Built target symal\n",
      "[ 64%] Built target plain2snt\n",
      "[ 67%] Built target snt2plain\n",
      "[ 70%] Built target snt2coocrmp\n",
      "[ 73%] Built target snt2cooc\n",
      "[100%] Built target mkcls\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"\"\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/lib/libmgiza.a\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: inst/lib/libmgiza.a(collCounts.cpp.o) has no symbols\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: inst/lib/libmgiza.a(HMMTables.cpp.o) has no symbols\n",
      "/Library/Developer/CommandLineTools/usr/bin/ranlib: file: inst/lib/libmgiza.a(SetArray.cpp.o) has no symbols\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./mgiza\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./snt2cooc\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./snt2plain\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./plain2snt\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./symal\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./hmmnorm\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./d4norm\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./snt2coocrmp\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./mkcls\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./force-align-moses.sh\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./giza2bal.pl\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./merge_alignment.py\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./plain2snt-hasvcb.py\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./sntpostproc.py\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./force-align-moses-old.sh\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./run.sh\n",
      "-- Installing: /Users/leo/Downloads/test/FlexNeuART/mgiza/mgizapp/inst/./snt2cooc.pl\n",
      "gcc -g -I.  -Wall -DVERSIONID=\\\"9.0.7\\\"  -o trec_eval trec_eval.c formats.c meas_init.c meas_acc.c meas_avg.c meas_print_single.c meas_print_final.c get_qrels.c get_trec_results.c get_prefs.c get_qrels_prefs.c get_qrels_jg.c form_res_rels.c form_res_rels_jg.c form_prefs_counts.c utility_pool.c get_zscores.c convert_zscores.c measures.c  m_map.c m_P.c m_num_q.c m_num_ret.c m_num_rel.c m_num_rel_ret.c m_gm_map.c m_Rprec.c m_recip_rank.c m_bpref.c m_iprec_at_recall.c m_recall.c m_Rprec_mult.c m_utility.c m_11pt_avg.c m_ndcg.c m_ndcg_cut.c m_Rndcg.c m_ndcg_rel.c m_binG.c m_G.c m_rel_P.c m_success.c m_infap.c m_map_cut.c m_gm_bpref.c m_runid.c m_relstring.c m_set_P.c m_set_recall.c m_set_rel_P.c m_set_map.c m_set_F.c m_num_nonrel_judged_ret.c m_prefs_num_prefs_poss.c m_prefs_num_prefs_ful.c m_prefs_num_prefs_ful_ret.c m_prefs_simp.c m_prefs_pair.c m_prefs_avgjg.c m_prefs_avgjg_Rnonrel.c m_prefs_simp_ret.c m_prefs_pair_ret.c m_prefs_avgjg_ret.c m_prefs_avgjg_Rnonrel_ret.c m_prefs_simp_imp.c m_prefs_pair_imp.c m_prefs_avgjg_imp.c m_map_avgjg.c m_Rprec_mult_avgjg.c m_P_avgjg.c m_yaap.c -lm\n",
      "[\u001b[1;34mINFO\u001b[m] Scanning for projects...\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m-----------------------< \u001b[0;36medu.umass.ciir:RankLib\u001b[0;1m >-----------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1mBuilding RankLib 2.14\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--------------------------------[ jar ]---------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-clean-plugin:2.5:clean\u001b[m \u001b[1m(default-clean)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-resources-plugin:2.6:resources\u001b[m \u001b[1m(default-resources)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Using 'UTF-8' encoding to copy filtered resources.\n",
      "[\u001b[1;34mINFO\u001b[m] skip non existing resourceDirectory /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/src/main/resources\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-compiler-plugin:3.2:compile\u001b[m \u001b[1m(default-compile)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Changes detected - recompiling the module!\n",
      "[\u001b[1;34mINFO\u001b[m] Compiling 65 source files to /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/target/classes\n",
      "[\u001b[1;34mINFO\u001b[m] /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/src/ciir/umass/edu/learning/RankerFactory.java: /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/src/ciir/umass/edu/learning/RankerFactory.java uses or overrides a deprecated API.\n",
      "[\u001b[1;34mINFO\u001b[m] /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/src/ciir/umass/edu/learning/RankerFactory.java: Recompile with -Xlint:deprecation for details.\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-resources-plugin:2.6:testResources\u001b[m \u001b[1m(default-testResources)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Using 'UTF-8' encoding to copy filtered resources.\n",
      "[\u001b[1;34mINFO\u001b[m] skip non existing resourceDirectory /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/src/test/resources\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-compiler-plugin:3.2:testCompile\u001b[m \u001b[1m(default-testCompile)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Changes detected - recompiling the module!\n",
      "[\u001b[1;34mINFO\u001b[m] Compiling 2 source files to /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/target/test-classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-surefire-plugin:2.12.4:test\u001b[m \u001b[1m(default-test)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Surefire report directory: /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/target/surefire-reports\n",
      "\n",
      "-------------------------------------------------------\n",
      " T E S T S\n",
      "-------------------------------------------------------\n",
      "Running ciir.umass.edu.SimpleTest\n",
      "Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.073 sec\n",
      "Running ciir.umass.edu.eval.EvaluatorTest\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib15001978068626546613tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tCoordinate Ascent\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib5456253495915585467tmp\n",
      "\n",
      "[+] Coordinate Ascent's Parameters:\n",
      "No. of random restarts: 5\n",
      "No. of iterations to search in each direction: 25\n",
      "Tolerance: 0.001\n",
      "Regularization: No\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib15001978068626546613tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "Best score 1.000000 best weights:\n",
      "0.978474 \n",
      "-0.021526 \n",
      "[+] Random restart #2/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "[+] Random restart #3/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "1       | +16.883  | 1.0     | \n",
      "------------------------------\n",
      "[+] Random restart #4/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "1       | +16.883  | 1.0     | \n",
      "------------------------------\n",
      "[+] Random restart #5/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "Best model overall:\n",
      "0.978474 \n",
      "-0.021526 \n",
      "---------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 1.0\n",
      "---------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib5456253495915585467tmp\n",
      "Model:\t\tCoordinate Ascent\n",
      "[0.9784735812133072, -0.02152641878669278]\n",
      "Test Ranker: 0\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib10897182673219826593tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tMART\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib11952740706036917762tmp\n",
      "\n",
      "[+] MART's Parameters:\n",
      "No. of trees: 1000\n",
      "No. of leaves: 10\n",
      "No. of threshold candidates: 256\n",
      "Min leaf support: 1\n",
      "Learning rate: 0.1\n",
      "Stop early: 100 rounds without performance gain on validation data\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib10897182673219826593tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "---------------------------------\n",
      "Training starts...\n",
      "---------------------------------\n",
      "#iter   | MAP-T     | MAP-V     | \n",
      "---------------------------------\n",
      "1       | 1.0       | \n",
      "2       | 1.0       | \n",
      "3       | 1.0       | \n",
      "4       | 1.0       | \n",
      "5       | 1.0       | \n",
      "6       | 1.0       | \n",
      "7       | 1.0       | \n",
      "8       | 1.0       | \n",
      "9       | 1.0       | \n",
      "10      | 1.0       | \n",
      "11      | 1.0       | \n",
      "12      | 1.0       | \n",
      "13      | 1.0       | \n",
      "14      | 1.0       | \n",
      "15      | 1.0       | \n",
      "16      | 1.0       | \n",
      "17      | 1.0       | \n",
      "18      | 1.0       | \n",
      "19      | 1.0       | \n",
      "20      | 1.0       | \n",
      "21      | 1.0       | \n",
      "22      | 1.0       | \n",
      "23      | 1.0       | \n",
      "24      | 1.0       | \n",
      "25      | 1.0       | \n",
      "26      | 1.0       | \n",
      "27      | 1.0       | \n",
      "28      | 1.0       | \n",
      "29      | 1.0       | \n",
      "30      | 1.0       | \n",
      "31      | 1.0       | \n",
      "32      | 1.0       | \n",
      "33      | 1.0       | \n",
      "34      | 1.0       | \n",
      "35      | 1.0       | \n",
      "36      | 1.0       | \n",
      "37      | 1.0       | \n",
      "38      | 1.0       | \n",
      "39      | 1.0       | \n",
      "40      | 1.0       | \n",
      "41      | 1.0       | \n",
      "42      | 1.0       | \n",
      "43      | 1.0       | \n",
      "44      | 1.0       | \n",
      "45      | 1.0       | \n",
      "46      | 1.0       | \n",
      "47      | 1.0       | \n",
      "48      | 1.0       | \n",
      "49      | 1.0       | \n",
      "50      | 1.0       | \n",
      "51      | 1.0       | \n",
      "52      | 1.0       | \n",
      "53      | 1.0       | \n",
      "54      | 1.0       | \n",
      "55      | 1.0       | \n",
      "56      | 1.0       | \n",
      "57      | 1.0       | \n",
      "58      | 1.0       | \n",
      "59      | 1.0       | \n",
      "60      | 1.0       | \n",
      "61      | 1.0       | \n",
      "62      | 1.0       | \n",
      "63      | 1.0       | \n",
      "64      | 1.0       | \n",
      "65      | 1.0       | \n",
      "66      | 1.0       | \n",
      "67      | 1.0       | \n",
      "68      | 1.0       | \n",
      "69      | 1.0       | \n",
      "70      | 1.0       | \n",
      "71      | 1.0       | \n",
      "72      | 1.0       | \n",
      "73      | 1.0       | \n",
      "74      | 1.0       | \n",
      "75      | 1.0       | \n",
      "76      | 1.0       | \n",
      "77      | 1.0       | \n",
      "78      | 1.0       | \n",
      "79      | 1.0       | \n",
      "80      | 1.0       | \n",
      "81      | 1.0       | \n",
      "82      | 1.0       | \n",
      "83      | 1.0       | \n",
      "84      | 1.0       | \n",
      "85      | 1.0       | \n",
      "86      | 1.0       | \n",
      "87      | 1.0       | \n",
      "88      | 1.0       | \n",
      "89      | 1.0       | \n",
      "90      | 1.0       | \n",
      "91      | 1.0       | \n",
      "92      | 1.0       | \n",
      "93      | 1.0       | \n",
      "94      | 1.0       | \n",
      "95      | 1.0       | \n",
      "96      | 1.0       | \n",
      "97      | 1.0       | \n",
      "98      | 1.0       | \n",
      "99      | 1.0       | \n",
      "100     | 1.0       | \n",
      "101     | 1.0       | \n",
      "102     | 1.0       | \n",
      "103     | 1.0       | \n",
      "104     | 1.0       | \n",
      "105     | 1.0       | \n",
      "106     | 1.0       | \n",
      "107     | 1.0       | \n",
      "108     | 1.0       | \n",
      "109     | 1.0       | \n",
      "110     | 1.0       | \n",
      "111     | 1.0       | \n",
      "112     | 1.0       | \n",
      "113     | 1.0       | \n",
      "114     | 1.0       | \n",
      "115     | 1.0       | \n",
      "116     | 1.0       | \n",
      "117     | 1.0       | \n",
      "118     | 1.0       | \n",
      "119     | 1.0       | \n",
      "120     | 1.0       | \n",
      "121     | 1.0       | \n",
      "122     | 1.0       | \n",
      "123     | 1.0       | \n",
      "124     | 1.0       | \n",
      "125     | 1.0       | \n",
      "126     | 1.0       | \n",
      "127     | 1.0       | \n",
      "128     | 1.0       | \n",
      "129     | 1.0       | \n",
      "130     | 1.0       | \n",
      "131     | 1.0       | \n",
      "132     | 1.0       | \n",
      "133     | 1.0       | \n",
      "134     | 1.0       | \n",
      "135     | 1.0       | \n",
      "136     | 1.0       | \n",
      "137     | 1.0       | \n",
      "138     | 1.0       | \n",
      "139     | 1.0       | \n",
      "140     | 1.0       | \n",
      "141     | 1.0       | \n",
      "142     | 1.0       | \n",
      "143     | 1.0       | \n",
      "144     | 1.0       | \n",
      "145     | 1.0       | \n",
      "146     | 1.0       | \n",
      "147     | 1.0       | \n",
      "148     | 1.0       | \n",
      "149     | 1.0       | \n",
      "150     | 1.0       | \n",
      "151     | 1.0       | \n",
      "152     | 1.0       | \n",
      "153     | 1.0       | \n",
      "154     | 1.0       | \n",
      "155     | 1.0       | \n",
      "156     | 1.0       | \n",
      "157     | 1.0       | \n",
      "158     | 1.0       | \n",
      "159     | 1.0       | \n",
      "160     | 1.0       | \n",
      "161     | 1.0       | \n",
      "162     | 1.0       | \n",
      "163     | 1.0       | \n",
      "164     | 1.0       | \n",
      "165     | 1.0       | \n",
      "166     | 1.0       | \n",
      "167     | 1.0       | \n",
      "168     | 1.0       | \n",
      "169     | 1.0       | \n",
      "170     | 1.0       | \n",
      "171     | 1.0       | \n",
      "172     | 1.0       | \n",
      "173     | 1.0       | \n",
      "174     | 1.0       | \n",
      "175     | 1.0       | \n",
      "176     | 1.0       | \n",
      "177     | 1.0       | \n",
      "178     | 1.0       | \n",
      "179     | 1.0       | \n",
      "180     | 1.0       | \n",
      "181     | 1.0       | \n",
      "182     | 1.0       | \n",
      "183     | 1.0       | \n",
      "184     | 1.0       | \n",
      "185     | 1.0       | \n",
      "186     | 1.0       | \n",
      "187     | 1.0       | \n",
      "188     | 1.0       | \n",
      "189     | 1.0       | \n",
      "190     | 1.0       | \n",
      "191     | 1.0       | \n",
      "192     | 1.0       | \n",
      "193     | 1.0       | \n",
      "194     | 1.0       | \n",
      "195     | 1.0       | \n",
      "196     | 1.0       | \n",
      "197     | 1.0       | \n",
      "198     | 1.0       | \n",
      "199     | 1.0       | \n",
      "200     | 1.0       | \n",
      "201     | 1.0       | \n",
      "202     | 1.0       | \n",
      "203     | 1.0       | \n",
      "204     | 1.0       | \n",
      "205     | 1.0       | \n",
      "206     | 1.0       | \n",
      "207     | 1.0       | \n",
      "208     | 1.0       | \n",
      "209     | 1.0       | \n",
      "210     | 1.0       | \n",
      "211     | 1.0       | \n",
      "212     | 1.0       | \n",
      "213     | 1.0       | \n",
      "214     | 1.0       | \n",
      "215     | 1.0       | \n",
      "216     | 1.0       | \n",
      "217     | 1.0       | \n",
      "218     | 1.0       | \n",
      "219     | 1.0       | \n",
      "220     | 1.0       | \n",
      "221     | 1.0       | \n",
      "222     | 1.0       | \n",
      "223     | 1.0       | \n",
      "224     | 1.0       | \n",
      "225     | 1.0       | \n",
      "226     | 1.0       | \n",
      "227     | 1.0       | \n",
      "228     | 1.0       | \n",
      "229     | 1.0       | \n",
      "230     | 1.0       | \n",
      "231     | 1.0       | \n",
      "232     | 1.0       | \n",
      "233     | 1.0       | \n",
      "234     | 1.0       | \n",
      "235     | 1.0       | \n",
      "236     | 1.0       | \n",
      "237     | 1.0       | \n",
      "238     | 1.0       | \n",
      "239     | 1.0       | \n",
      "240     | 1.0       | \n",
      "241     | 1.0       | \n",
      "242     | 1.0       | \n",
      "243     | 1.0       | \n",
      "244     | 1.0       | \n",
      "245     | 1.0       | \n",
      "246     | 1.0       | \n",
      "247     | 1.0       | \n",
      "248     | 1.0       | \n",
      "249     | 1.0       | \n",
      "250     | 1.0       | \n",
      "251     | 1.0       | \n",
      "252     | 1.0       | \n",
      "253     | 1.0       | \n",
      "254     | 1.0       | \n",
      "255     | 1.0       | \n",
      "256     | 1.0       | \n",
      "257     | 1.0       | \n",
      "258     | 1.0       | \n",
      "259     | 1.0       | \n",
      "260     | 1.0       | \n",
      "261     | 1.0       | \n",
      "262     | 1.0       | \n",
      "263     | 1.0       | \n",
      "264     | 1.0       | \n",
      "265     | 1.0       | \n",
      "266     | 1.0       | \n",
      "267     | 1.0       | \n",
      "268     | 1.0       | \n",
      "269     | 1.0       | \n",
      "270     | 1.0       | \n",
      "271     | 1.0       | \n",
      "272     | 1.0       | \n",
      "273     | 1.0       | \n",
      "274     | 1.0       | \n",
      "275     | 1.0       | \n",
      "276     | 1.0       | \n",
      "277     | 1.0       | \n",
      "278     | 1.0       | \n",
      "279     | 1.0       | \n",
      "280     | 1.0       | \n",
      "281     | 1.0       | \n",
      "282     | 1.0       | \n",
      "283     | 1.0       | \n",
      "284     | 1.0       | \n",
      "285     | 1.0       | \n",
      "286     | 1.0       | \n",
      "287     | 1.0       | \n",
      "288     | 1.0       | \n",
      "289     | 1.0       | \n",
      "290     | 1.0       | \n",
      "291     | 1.0       | \n",
      "292     | 1.0       | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293     | 1.0       | \n",
      "294     | 1.0       | \n",
      "295     | 1.0       | \n",
      "296     | 1.0       | \n",
      "297     | 1.0       | \n",
      "298     | 1.0       | \n",
      "299     | 1.0       | \n",
      "300     | 1.0       | \n",
      "301     | 1.0       | \n",
      "302     | 1.0       | \n",
      "303     | 1.0       | \n",
      "304     | 1.0       | \n",
      "305     | 1.0       | \n",
      "306     | 1.0       | \n",
      "307     | 1.0       | \n",
      "308     | 1.0       | \n",
      "309     | 1.0       | \n",
      "310     | 1.0       | \n",
      "311     | 1.0       | \n",
      "312     | 1.0       | \n",
      "313     | 1.0       | \n",
      "314     | 1.0       | \n",
      "315     | 1.0       | \n",
      "316     | 1.0       | \n",
      "317     | 1.0       | \n",
      "318     | 1.0       | \n",
      "319     | 1.0       | \n",
      "320     | 1.0       | \n",
      "321     | 1.0       | \n",
      "322     | 1.0       | \n",
      "323     | 1.0       | \n",
      "324     | 1.0       | \n",
      "325     | 1.0       | \n",
      "326     | 1.0       | \n",
      "327     | 1.0       | \n",
      "328     | 1.0       | \n",
      "329     | 1.0       | \n",
      "330     | 1.0       | \n",
      "331     | 1.0       | \n",
      "332     | 1.0       | \n",
      "333     | 1.0       | \n",
      "334     | 1.0       | \n",
      "335     | 1.0       | \n",
      "336     | 1.0       | \n",
      "337     | 1.0       | \n",
      "338     | 1.0       | \n",
      "339     | 1.0       | \n",
      "340     | 1.0       | \n",
      "341     | 1.0       | \n",
      "342     | 1.0       | \n",
      "343     | 1.0       | \n",
      "344     | 1.0       | \n",
      "345     | 1.0       | \n",
      "346     | 1.0       | \n",
      "347     | 1.0       | \n",
      "348     | 1.0       | \n",
      "349     | 1.0       | \n",
      "350     | 1.0       | \n",
      "351     | 1.0       | \n",
      "352     | 1.0       | \n",
      "353     | 1.0       | \n",
      "354     | 1.0       | \n",
      "355     | 1.0       | \n",
      "356     | 1.0       | \n",
      "357     | 1.0       | \n",
      "358     | 1.0       | \n",
      "359     | 1.0       | \n",
      "360     | 1.0       | \n",
      "361     | 1.0       | \n",
      "362     | 1.0       | \n",
      "363     | 1.0       | \n",
      "364     | 1.0       | \n",
      "365     | 1.0       | \n",
      "366     | 1.0       | \n",
      "367     | 1.0       | \n",
      "368     | 1.0       | \n",
      "369     | 1.0       | \n",
      "370     | 1.0       | \n",
      "371     | 1.0       | \n",
      "372     | 1.0       | \n",
      "373     | 1.0       | \n",
      "374     | 1.0       | \n",
      "375     | 1.0       | \n",
      "376     | 1.0       | \n",
      "377     | 1.0       | \n",
      "378     | 1.0       | \n",
      "379     | 1.0       | \n",
      "380     | 1.0       | \n",
      "381     | 1.0       | \n",
      "382     | 1.0       | \n",
      "383     | 1.0       | \n",
      "384     | 1.0       | \n",
      "385     | 1.0       | \n",
      "386     | 1.0       | \n",
      "387     | 1.0       | \n",
      "388     | 1.0       | \n",
      "389     | 1.0       | \n",
      "390     | 1.0       | \n",
      "391     | 1.0       | \n",
      "392     | 1.0       | \n",
      "393     | 1.0       | \n",
      "394     | 1.0       | \n",
      "395     | 1.0       | \n",
      "396     | 1.0       | \n",
      "397     | 1.0       | \n",
      "398     | 1.0       | \n",
      "399     | 1.0       | \n",
      "400     | 1.0       | \n",
      "401     | 1.0       | \n",
      "402     | 1.0       | \n",
      "403     | 1.0       | \n",
      "404     | 1.0       | \n",
      "405     | 1.0       | \n",
      "406     | 1.0       | \n",
      "407     | 1.0       | \n",
      "408     | 1.0       | \n",
      "409     | 1.0       | \n",
      "410     | 1.0       | \n",
      "411     | 1.0       | \n",
      "412     | 1.0       | \n",
      "413     | 1.0       | \n",
      "414     | 1.0       | \n",
      "415     | 1.0       | \n",
      "416     | 1.0       | \n",
      "417     | 1.0       | \n",
      "418     | 1.0       | \n",
      "419     | 1.0       | \n",
      "420     | 1.0       | \n",
      "421     | 1.0       | \n",
      "422     | 1.0       | \n",
      "423     | 1.0       | \n",
      "424     | 1.0       | \n",
      "425     | 1.0       | \n",
      "426     | 1.0       | \n",
      "427     | 1.0       | \n",
      "428     | 1.0       | \n",
      "429     | 1.0       | \n",
      "430     | 1.0       | \n",
      "431     | 1.0       | \n",
      "432     | 1.0       | \n",
      "433     | 1.0       | \n",
      "434     | 1.0       | \n",
      "435     | 1.0       | \n",
      "436     | 1.0       | \n",
      "437     | 1.0       | \n",
      "438     | 1.0       | \n",
      "439     | 1.0       | \n",
      "440     | 1.0       | \n",
      "441     | 1.0       | \n",
      "442     | 1.0       | \n",
      "443     | 1.0       | \n",
      "444     | 1.0       | \n",
      "445     | 1.0       | \n",
      "446     | 1.0       | \n",
      "447     | 1.0       | \n",
      "448     | 1.0       | \n",
      "449     | 1.0       | \n",
      "450     | 1.0       | \n",
      "451     | 1.0       | \n",
      "452     | 1.0       | \n",
      "453     | 1.0       | \n",
      "454     | 1.0       | \n",
      "455     | 1.0       | \n",
      "456     | 1.0       | \n",
      "457     | 1.0       | \n",
      "458     | 1.0       | \n",
      "459     | 1.0       | \n",
      "460     | 1.0       | \n",
      "461     | 1.0       | \n",
      "462     | 1.0       | \n",
      "463     | 1.0       | \n",
      "464     | 1.0       | \n",
      "465     | 1.0       | \n",
      "466     | 1.0       | \n",
      "467     | 1.0       | \n",
      "468     | 1.0       | \n",
      "469     | 1.0       | \n",
      "470     | 1.0       | \n",
      "471     | 1.0       | \n",
      "472     | 1.0       | \n",
      "473     | 1.0       | \n",
      "474     | 1.0       | \n",
      "475     | 1.0       | \n",
      "476     | 1.0       | \n",
      "477     | 1.0       | \n",
      "478     | 1.0       | \n",
      "479     | 1.0       | \n",
      "480     | 1.0       | \n",
      "481     | 1.0       | \n",
      "482     | 1.0       | \n",
      "483     | 1.0       | \n",
      "484     | 1.0       | \n",
      "485     | 1.0       | \n",
      "486     | 1.0       | \n",
      "487     | 1.0       | \n",
      "488     | 1.0       | \n",
      "489     | 1.0       | \n",
      "490     | 1.0       | \n",
      "491     | 1.0       | \n",
      "492     | 1.0       | \n",
      "493     | 1.0       | \n",
      "494     | 1.0       | \n",
      "495     | 1.0       | \n",
      "496     | 1.0       | \n",
      "497     | 1.0       | \n",
      "498     | 1.0       | \n",
      "499     | 1.0       | \n",
      "500     | 1.0       | \n",
      "501     | 1.0       | \n",
      "502     | 1.0       | \n",
      "503     | 1.0       | \n",
      "504     | 1.0       | \n",
      "505     | 1.0       | \n",
      "506     | 1.0       | \n",
      "507     | 1.0       | \n",
      "508     | 1.0       | \n",
      "509     | 1.0       | \n",
      "510     | 1.0       | \n",
      "511     | 1.0       | \n",
      "512     | 1.0       | \n",
      "513     | 1.0       | \n",
      "514     | 1.0       | \n",
      "515     | 1.0       | \n",
      "516     | 1.0       | \n",
      "517     | 1.0       | \n",
      "518     | 1.0       | \n",
      "519     | 1.0       | \n",
      "520     | 1.0       | \n",
      "521     | 1.0       | \n",
      "522     | 1.0       | \n",
      "523     | 1.0       | \n",
      "524     | 1.0       | \n",
      "525     | 1.0       | \n",
      "526     | 1.0       | \n",
      "527     | 1.0       | \n",
      "528     | 1.0       | \n",
      "529     | 1.0       | \n",
      "530     | 1.0       | \n",
      "531     | 1.0       | \n",
      "532     | 1.0       | \n",
      "533     | 1.0       | \n",
      "534     | 1.0       | \n",
      "535     | 1.0       | \n",
      "536     | 1.0       | \n",
      "537     | 1.0       | \n",
      "538     | 1.0       | \n",
      "539     | 1.0       | \n",
      "540     | 1.0       | \n",
      "541     | 1.0       | \n",
      "542     | 1.0       | \n",
      "543     | 1.0       | \n",
      "544     | 1.0       | \n",
      "545     | 1.0       | \n",
      "546     | 1.0       | \n",
      "547     | 1.0       | \n",
      "548     | 1.0       | \n",
      "549     | 1.0       | \n",
      "550     | 1.0       | \n",
      "551     | 1.0       | \n",
      "552     | 1.0       | \n",
      "553     | 1.0       | \n",
      "554     | 1.0       | \n",
      "555     | 1.0       | \n",
      "556     | 1.0       | \n",
      "557     | 1.0       | \n",
      "558     | 1.0       | \n",
      "559     | 1.0       | \n",
      "560     | 1.0       | \n",
      "561     | 1.0       | \n",
      "562     | 1.0       | \n",
      "563     | 1.0       | \n",
      "564     | 1.0       | \n",
      "565     | 1.0       | \n",
      "566     | 1.0       | \n",
      "567     | 1.0       | \n",
      "568     | 1.0       | \n",
      "569     | 1.0       | \n",
      "570     | 1.0       | \n",
      "571     | 1.0       | \n",
      "572     | 1.0       | \n",
      "573     | 1.0       | \n",
      "574     | 1.0       | \n",
      "575     | 1.0       | \n",
      "576     | 1.0       | \n",
      "577     | 1.0       | \n",
      "578     | 1.0       | \n",
      "579     | 1.0       | \n",
      "580     | 1.0       | \n",
      "581     | 1.0       | \n",
      "582     | 1.0       | \n",
      "583     | 1.0       | \n",
      "584     | 1.0       | \n",
      "585     | 1.0       | \n",
      "586     | 1.0       | \n",
      "587     | 1.0       | \n",
      "588     | 1.0       | \n",
      "589     | 1.0       | \n",
      "590     | 1.0       | \n",
      "591     | 1.0       | \n",
      "592     | 1.0       | \n",
      "593     | 1.0       | \n",
      "594     | 1.0       | \n",
      "595     | 1.0       | \n",
      "596     | 1.0       | \n",
      "597     | 1.0       | \n",
      "598     | 1.0       | \n",
      "599     | 1.0       | \n",
      "600     | 1.0       | \n",
      "601     | 1.0       | \n",
      "602     | 1.0       | \n",
      "603     | 1.0       | \n",
      "604     | 1.0       | \n",
      "605     | 1.0       | \n",
      "606     | 1.0       | \n",
      "607     | 1.0       | \n",
      "608     | 1.0       | \n",
      "609     | 1.0       | \n",
      "610     | 1.0       | \n",
      "611     | 1.0       | \n",
      "612     | 1.0       | \n",
      "613     | 1.0       | \n",
      "614     | 1.0       | \n",
      "615     | 1.0       | \n",
      "616     | 1.0       | \n",
      "617     | 1.0       | \n",
      "618     | 1.0       | \n",
      "619     | 1.0       | \n",
      "620     | 1.0       | \n",
      "621     | 1.0       | \n",
      "622     | 1.0       | \n",
      "623     | 1.0       | \n",
      "624     | 1.0       | \n",
      "625     | 1.0       | \n",
      "626     | 1.0       | \n",
      "627     | 1.0       | \n",
      "628     | 1.0       | \n",
      "629     | 1.0       | \n",
      "630     | 1.0       | \n",
      "631     | 1.0       | \n",
      "632     | 1.0       | \n",
      "633     | 1.0       | \n",
      "634     | 1.0       | \n",
      "635     | 1.0       | \n",
      "636     | 1.0       | \n",
      "637     | 1.0       | \n",
      "638     | 1.0       | \n",
      "639     | 1.0       | \n",
      "640     | 1.0       | \n",
      "641     | 1.0       | \n",
      "642     | 1.0       | \n",
      "643     | 1.0       | \n",
      "644     | 1.0       | \n",
      "645     | 1.0       | \n",
      "646     | 1.0       | \n",
      "647     | 1.0       | \n",
      "648     | 1.0       | \n",
      "649     | 1.0       | \n",
      "650     | 1.0       | \n",
      "651     | 1.0       | \n",
      "652     | 1.0       | \n",
      "653     | 1.0       | \n",
      "654     | 1.0       | \n",
      "655     | 1.0       | \n",
      "656     | 1.0       | \n",
      "657     | 1.0       | \n",
      "658     | 1.0       | \n",
      "659     | 1.0       | \n",
      "660     | 1.0       | \n",
      "661     | 1.0       | \n",
      "662     | 1.0       | \n",
      "663     | 1.0       | \n",
      "664     | 1.0       | \n",
      "665     | 1.0       | \n",
      "666     | 1.0       | \n",
      "667     | 1.0       | \n",
      "668     | 1.0       | \n",
      "669     | 1.0       | \n",
      "670     | 1.0       | \n",
      "671     | 1.0       | \n",
      "672     | 1.0       | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673     | 1.0       | \n",
      "674     | 1.0       | \n",
      "675     | 1.0       | \n",
      "676     | 1.0       | \n",
      "677     | 1.0       | \n",
      "678     | 1.0       | \n",
      "679     | 1.0       | \n",
      "680     | 1.0       | \n",
      "681     | 1.0       | \n",
      "682     | 1.0       | \n",
      "683     | 1.0       | \n",
      "684     | 1.0       | \n",
      "685     | 1.0       | \n",
      "686     | 1.0       | \n",
      "687     | 1.0       | \n",
      "688     | 1.0       | \n",
      "689     | 1.0       | \n",
      "690     | 1.0       | \n",
      "691     | 1.0       | \n",
      "692     | 1.0       | \n",
      "693     | 1.0       | \n",
      "694     | 1.0       | \n",
      "695     | 1.0       | \n",
      "696     | 1.0       | \n",
      "697     | 1.0       | \n",
      "698     | 1.0       | \n",
      "699     | 1.0       | \n",
      "700     | 1.0       | \n",
      "701     | 1.0       | \n",
      "702     | 1.0       | \n",
      "703     | 1.0       | \n",
      "704     | 1.0       | \n",
      "705     | 1.0       | \n",
      "706     | 1.0       | \n",
      "707     | 1.0       | \n",
      "708     | 1.0       | \n",
      "709     | 1.0       | \n",
      "710     | 1.0       | \n",
      "711     | 1.0       | \n",
      "712     | 1.0       | \n",
      "713     | 1.0       | \n",
      "714     | 1.0       | \n",
      "715     | 1.0       | \n",
      "716     | 1.0       | \n",
      "717     | 1.0       | \n",
      "718     | 1.0       | \n",
      "719     | 1.0       | \n",
      "720     | 1.0       | \n",
      "721     | 1.0       | \n",
      "722     | 1.0       | \n",
      "723     | 1.0       | \n",
      "724     | 1.0       | \n",
      "725     | 1.0       | \n",
      "726     | 1.0       | \n",
      "727     | 1.0       | \n",
      "728     | 1.0       | \n",
      "729     | 1.0       | \n",
      "730     | 1.0       | \n",
      "731     | 1.0       | \n",
      "732     | 1.0       | \n",
      "733     | 1.0       | \n",
      "734     | 1.0       | \n",
      "735     | 1.0       | \n",
      "736     | 1.0       | \n",
      "737     | 1.0       | \n",
      "738     | 1.0       | \n",
      "739     | 1.0       | \n",
      "740     | 1.0       | \n",
      "741     | 1.0       | \n",
      "742     | 1.0       | \n",
      "743     | 1.0       | \n",
      "744     | 1.0       | \n",
      "745     | 1.0       | \n",
      "746     | 1.0       | \n",
      "747     | 1.0       | \n",
      "748     | 1.0       | \n",
      "749     | 1.0       | \n",
      "750     | 1.0       | \n",
      "751     | 1.0       | \n",
      "752     | 1.0       | \n",
      "753     | 1.0       | \n",
      "754     | 1.0       | \n",
      "755     | 1.0       | \n",
      "756     | 1.0       | \n",
      "757     | 1.0       | \n",
      "758     | 1.0       | \n",
      "759     | 1.0       | \n",
      "760     | 1.0       | \n",
      "761     | 1.0       | \n",
      "762     | 1.0       | \n",
      "763     | 1.0       | \n",
      "764     | 1.0       | \n",
      "765     | 1.0       | \n",
      "766     | 1.0       | \n",
      "767     | 1.0       | \n",
      "768     | 1.0       | \n",
      "769     | 1.0       | \n",
      "770     | 1.0       | \n",
      "771     | 1.0       | \n",
      "772     | 1.0       | \n",
      "773     | 1.0       | \n",
      "774     | 1.0       | \n",
      "775     | 1.0       | \n",
      "776     | 1.0       | \n",
      "777     | 1.0       | \n",
      "778     | 1.0       | \n",
      "779     | 1.0       | \n",
      "780     | 1.0       | \n",
      "781     | 1.0       | \n",
      "782     | 1.0       | \n",
      "783     | 1.0       | \n",
      "784     | 1.0       | \n",
      "785     | 1.0       | \n",
      "786     | 1.0       | \n",
      "787     | 1.0       | \n",
      "788     | 1.0       | \n",
      "789     | 1.0       | \n",
      "790     | 1.0       | \n",
      "791     | 1.0       | \n",
      "792     | 1.0       | \n",
      "793     | 1.0       | \n",
      "794     | 1.0       | \n",
      "795     | 1.0       | \n",
      "796     | 1.0       | \n",
      "797     | 1.0       | \n",
      "798     | 1.0       | \n",
      "799     | 1.0       | \n",
      "800     | 1.0       | \n",
      "801     | 1.0       | \n",
      "802     | 1.0       | \n",
      "803     | 1.0       | \n",
      "804     | 1.0       | \n",
      "805     | 1.0       | \n",
      "806     | 1.0       | \n",
      "807     | 1.0       | \n",
      "808     | 1.0       | \n",
      "809     | 1.0       | \n",
      "810     | 1.0       | \n",
      "811     | 1.0       | \n",
      "812     | 1.0       | \n",
      "813     | 1.0       | \n",
      "814     | 1.0       | \n",
      "815     | 1.0       | \n",
      "816     | 1.0       | \n",
      "817     | 1.0       | \n",
      "818     | 1.0       | \n",
      "819     | 1.0       | \n",
      "820     | 1.0       | \n",
      "821     | 1.0       | \n",
      "822     | 1.0       | \n",
      "823     | 1.0       | \n",
      "824     | 1.0       | \n",
      "825     | 1.0       | \n",
      "826     | 1.0       | \n",
      "827     | 1.0       | \n",
      "828     | 1.0       | \n",
      "829     | 1.0       | \n",
      "830     | 1.0       | \n",
      "831     | 1.0       | \n",
      "832     | 1.0       | \n",
      "833     | 1.0       | \n",
      "834     | 1.0       | \n",
      "835     | 1.0       | \n",
      "836     | 1.0       | \n",
      "837     | 1.0       | \n",
      "838     | 1.0       | \n",
      "839     | 1.0       | \n",
      "840     | 1.0       | \n",
      "841     | 1.0       | \n",
      "842     | 1.0       | \n",
      "843     | 1.0       | \n",
      "844     | 1.0       | \n",
      "845     | 1.0       | \n",
      "846     | 1.0       | \n",
      "847     | 1.0       | \n",
      "848     | 1.0       | \n",
      "849     | 1.0       | \n",
      "850     | 1.0       | \n",
      "851     | 1.0       | \n",
      "852     | 1.0       | \n",
      "853     | 1.0       | \n",
      "854     | 1.0       | \n",
      "855     | 1.0       | \n",
      "856     | 1.0       | \n",
      "857     | 1.0       | \n",
      "858     | 1.0       | \n",
      "859     | 1.0       | \n",
      "860     | 1.0       | \n",
      "861     | 1.0       | \n",
      "862     | 1.0       | \n",
      "863     | 1.0       | \n",
      "864     | 1.0       | \n",
      "865     | 1.0       | \n",
      "866     | 1.0       | \n",
      "867     | 1.0       | \n",
      "868     | 1.0       | \n",
      "869     | 1.0       | \n",
      "870     | 1.0       | \n",
      "871     | 1.0       | \n",
      "872     | 1.0       | \n",
      "873     | 1.0       | \n",
      "874     | 1.0       | \n",
      "875     | 1.0       | \n",
      "876     | 1.0       | \n",
      "877     | 1.0       | \n",
      "878     | 1.0       | \n",
      "879     | 1.0       | \n",
      "880     | 1.0       | \n",
      "881     | 1.0       | \n",
      "882     | 1.0       | \n",
      "883     | 1.0       | \n",
      "884     | 1.0       | \n",
      "885     | 1.0       | \n",
      "886     | 1.0       | \n",
      "887     | 1.0       | \n",
      "888     | 1.0       | \n",
      "889     | 1.0       | \n",
      "890     | 1.0       | \n",
      "891     | 1.0       | \n",
      "892     | 1.0       | \n",
      "893     | 1.0       | \n",
      "894     | 1.0       | \n",
      "895     | 1.0       | \n",
      "896     | 1.0       | \n",
      "897     | 1.0       | \n",
      "898     | 1.0       | \n",
      "899     | 1.0       | \n",
      "900     | 1.0       | \n",
      "901     | 1.0       | \n",
      "902     | 1.0       | \n",
      "903     | 1.0       | \n",
      "904     | 1.0       | \n",
      "905     | 1.0       | \n",
      "906     | 1.0       | \n",
      "907     | 1.0       | \n",
      "908     | 1.0       | \n",
      "909     | 1.0       | \n",
      "910     | 1.0       | \n",
      "911     | 1.0       | \n",
      "912     | 1.0       | \n",
      "913     | 1.0       | \n",
      "914     | 1.0       | \n",
      "915     | 1.0       | \n",
      "916     | 1.0       | \n",
      "917     | 1.0       | \n",
      "918     | 1.0       | \n",
      "919     | 1.0       | \n",
      "920     | 1.0       | \n",
      "921     | 1.0       | \n",
      "922     | 1.0       | \n",
      "923     | 1.0       | \n",
      "924     | 1.0       | \n",
      "925     | 1.0       | \n",
      "926     | 1.0       | \n",
      "927     | 1.0       | \n",
      "928     | 1.0       | \n",
      "929     | 1.0       | \n",
      "930     | 1.0       | \n",
      "931     | 1.0       | \n",
      "932     | 1.0       | \n",
      "933     | 1.0       | \n",
      "934     | 1.0       | \n",
      "935     | 1.0       | \n",
      "936     | 1.0       | \n",
      "937     | 1.0       | \n",
      "938     | 1.0       | \n",
      "939     | 1.0       | \n",
      "940     | 1.0       | \n",
      "941     | 1.0       | \n",
      "942     | 1.0       | \n",
      "943     | 1.0       | \n",
      "944     | 1.0       | \n",
      "945     | 1.0       | \n",
      "946     | 1.0       | \n",
      "947     | 1.0       | \n",
      "948     | 1.0       | \n",
      "949     | 1.0       | \n",
      "950     | 1.0       | \n",
      "951     | 1.0       | \n",
      "952     | 1.0       | \n",
      "953     | 1.0       | \n",
      "954     | 1.0       | \n",
      "955     | 1.0       | \n",
      "956     | 1.0       | \n",
      "957     | 1.0       | \n",
      "958     | 1.0       | \n",
      "959     | 1.0       | \n",
      "960     | 1.0       | \n",
      "961     | 1.0       | \n",
      "962     | 1.0       | \n",
      "963     | 1.0       | \n",
      "964     | 1.0       | \n",
      "965     | 1.0       | \n",
      "966     | 1.0       | \n",
      "967     | 1.0       | \n",
      "968     | 1.0       | \n",
      "969     | 1.0       | \n",
      "970     | 1.0       | \n",
      "971     | 1.0       | \n",
      "972     | 1.0       | \n",
      "973     | 1.0       | \n",
      "974     | 1.0       | \n",
      "975     | 1.0       | \n",
      "976     | 1.0       | \n",
      "977     | 1.0       | \n",
      "978     | 1.0       | \n",
      "979     | 1.0       | \n",
      "980     | 1.0       | \n",
      "981     | 1.0       | \n",
      "982     | 1.0       | \n",
      "983     | 1.0       | \n",
      "984     | 1.0       | \n",
      "985     | 1.0       | \n",
      "986     | 1.0       | \n",
      "987     | 1.0       | \n",
      "988     | 1.0       | \n",
      "989     | 1.0       | \n",
      "990     | 1.0       | \n",
      "991     | 1.0       | \n",
      "992     | 1.0       | \n",
      "993     | 1.0       | \n",
      "994     | 1.0       | \n",
      "995     | 1.0       | \n",
      "996     | 1.0       | \n",
      "997     | 1.0       | \n",
      "998     | 1.0       | \n",
      "999     | 1.0       | \n",
      "1000    | 1.0       | \n",
      "---------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 1.0\n",
      "---------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib11952740706036917762tmp\n",
      "\n",
      "Discard orig. features\n",
      "Model file:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib11952740706036917762tmp\n",
      "Feature normalization: No\n",
      "Model:\t\tMART\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib10897182673219826593tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Test Ranker: 9\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib15300092803681136981tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tLinear Regression\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib3598702382664619174tmp\n",
      "\n",
      "[+] Linear Regression's Parameters:\n",
      "L2-norm regularization: lambda = 1.0E-10\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib15300092803681136981tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "--------------------------------\n",
      "Training starts...\n",
      "--------------------------------\n",
      "Learning the least square model... [Done]\n",
      "---------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 0.8338\n",
      "---------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib3598702382664619174tmp\n",
      "\n",
      "Discard orig. features\n",
      "Model file:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib3598702382664619174tmp\n",
      "Feature normalization: No\n",
      "Model:\t\tLinear Regression\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib15300092803681136981tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ranker: 8\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib672454452183854136tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tRandom Forests\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib9534616344457594800tmp\n",
      "\n",
      "[+] Random Forests's Parameters:\n",
      "No. of bags: 10\n",
      "Sub-sampling: 1.0\n",
      "Feature-sampling: 1.0\n",
      "No. of trees: 1\n",
      "No. of leaves: 100\n",
      "No. of threshold candidates: 256\n",
      "Learning rate: 0.1\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib672454452183854136tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "------------------------------------\n",
      "Training starts...\n",
      "------------------------------------\n",
      "bag       | MAP-B     | MAP-OOB     | \n",
      "------------------------------------\n",
      "b[1]      | 1.0       | \n",
      "b[2]      | 1.0       | \n",
      "b[3]      | 1.0       | \n",
      "b[4]      | 1.0       | \n",
      "b[5]      | 1.0       | \n",
      "b[6]      | 1.0       | \n",
      "b[7]      | 1.0       | \n",
      "b[8]      | 1.0       | \n",
      "b[9]      | 1.0       | \n",
      "b[10]     | 1.0       | \n",
      "------------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 1.0\n",
      "------------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib9534616344457594800tmp\n",
      "\n",
      "Discard orig. features\n",
      "Model file:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib9534616344457594800tmp\n",
      "Feature normalization: No\n",
      "Model:\t\tRandom Forests\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib672454452183854136tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Test Ranker: 4\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib2659547944658700958tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tCoordinate Ascent\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib9277478551101895164tmp\n",
      "\n",
      "[+] Coordinate Ascent's Parameters:\n",
      "No. of random restarts: 5\n",
      "No. of iterations to search in each direction: 25\n",
      "Tolerance: 0.001\n",
      "Regularization: No\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib2659547944658700958tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "1       | +16.883  | 1.0     | \n",
      "------------------------------\n",
      "Best score 1.000000 best weights:\n",
      "0.971236 \n",
      "0.028764 \n",
      "[+] Random restart #2/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "[+] Random restart #3/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "[+] Random restart #4/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "[+] Random restart #5/5...\n",
      "Shuffling features' order... [Done.]\n",
      "Optimizing weight vector... \n",
      "------------------------------\n",
      "Feature | weight   | MAP     | \n",
      "------------------------------\n",
      "2       | -0.011   | 1.0     | \n",
      "------------------------------\n",
      "Best model overall:\n",
      "0.971236 \n",
      "0.028764 \n",
      "---------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 1.0\n",
      "---------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib9277478551101895164tmp\n",
      "\n",
      "Discard orig. features\n",
      "Model file:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib9277478551101895164tmp\n",
      "Feature normalization: No\n",
      "Model:\t\tCoordinate Ascent\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib2659547944658700958tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Test Ranker: 6\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib3848684402202638600tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tLambdaMART\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib6497817970384642487tmp\n",
      "\n",
      "[+] LambdaMART's Parameters:\n",
      "No. of trees: 1\n",
      "No. of leaves: 100\n",
      "No. of threshold candidates: 256\n",
      "Min leaf support: 1\n",
      "Learning rate: 0.1\n",
      "Stop early: -1 rounds without performance gain on validation data\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib3848684402202638600tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "---------------------------------\n",
      "Training starts...\n",
      "---------------------------------\n",
      "#iter   | MAP-T     | MAP-V     | \n",
      "---------------------------------\n",
      "1       | 1.0       | \n",
      "---------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 1.0\n",
      "---------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib6497817970384642487tmp\n",
      "\n",
      "Discard orig. features\n",
      "Model file:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib6497817970384642487tmp\n",
      "Feature normalization: No\n",
      "Model:\t\tLambdaMART\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib3848684402202638600tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Usage: java -jar RankLib.jar <Params>\n",
      "Params:\n",
      "  [+] Training (+ tuning and evaluation)\n",
      "\t-train <file>\t\tTraining data\n",
      "\t-ranker <type>\t\tSpecify which ranking algorithm to use\n",
      "\t\t\t\t0: MART (gradient boosted regression tree)\n",
      "\t\t\t\t1: RankNet\n",
      "\t\t\t\t2: RankBoost\n",
      "\t\t\t\t3: AdaRank\n",
      "\t\t\t\t4: Coordinate Ascent\n",
      "\t\t\t\t6: LambdaMART\n",
      "\t\t\t\t7: ListNet\n",
      "\t\t\t\t8: Random Forests\n",
      "\t\t\t\t9: Linear regression (L2 regularization)\n",
      "\t[ -feature <file> ]\tFeature description file: list features to be considered by the learner, each on a separate line\n",
      "\t\t\t\tIf not specified, all features will be used.\n",
      "\t[ -metric2t <metric> ]\tMetric to optimize on the training data.  Supported: MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)\n",
      "\t[ -gmax <label> ]\tHighest judged relevance label. It affects the calculation of ERR (default=4, i.e. 5-point scale {0,1,2,3,4})\n",
      "\t[ -qrel <file> ]\tTREC-style relevance judgment file. It only affects MAP and NDCG (default=unspecified)\n",
      "\t[ -silent ]\t\tDo not print progress messages (which are printed by default)\n",
      "\t[ -missingZero ]\tSubstitute zero for missing feature values rather than throwing an exception.\n",
      "\n",
      "\t[ -validate <file> ]\tSpecify if you want to tune your system on the validation data (default=unspecified)\n",
      "\t\t\t\tIf specified, the final model will be the one that performs best on the validation data\n",
      "\t[ -tvs <x \\in [0..1]> ]\tIf you don't have separate validation data, use this to set train-validation split to be (x)(1.0-x)\n",
      "\t[ -save <model> ]\tSave the model learned (default=not-save)\n",
      "\n",
      "\t[ -test <file> ]\tSpecify if you want to evaluate the trained model on this data (default=unspecified)\n",
      "\t[ -tts <x \\in [0..1]> ]\tSet train-test split to be (x)(1.0-x). -tts will override -tvs\n",
      "\t[ -metric2T <metric> ]\tMetric to evaluate on the test data (default to the same as specified for -metric2t)\n",
      "\n",
      "\t[ -norm <method>]\tNormalize all feature vectors (default=no-normalization). Method can be:\n",
      "\t\t\t\tsum: normalize each feature by the sum of all its values\n",
      "\t\t\t\tzscore: normalize each feature by its mean/standard deviation\n",
      "\t\t\t\tlinear: normalize each feature by its min/max values\n",
      "\n",
      "\t[ -kcv <k> ]\t\tSpecify if you want to perform k-fold cross validation using the specified training data (default=NoCV)\n",
      "\t\t\t\t-tvs can be used to further reserve a portion of the training data in each fold for validation\n",
      "\t[ -kcvmd <dir> ]\tDirectory for models trained via cross-validation (default=not-save)\n",
      "\t[ -kcvmn <model> ]\tName for model learned in each fold. It will be prefix-ed with the fold-number (default=empty)\n",
      "\n",
      "    [-] RankNet-specific parameters\n",
      "\t[ -epoch <T> ]\t\tThe number of epochs to train (default=10)\n",
      "\t[ -layer <layer> ]\tThe number of hidden layers (default=1)\n",
      "\t[ -node <node> ]\tThe number of hidden nodes per layer (default=10)\n",
      "\t[ -lr <rate> ]\t\tLearning rate (default=0.00005)\n",
      "\n",
      "    [-] RankBoost-specific parameters\n",
      "\t[ -round <T> ]\t\tThe number of rounds to train (default=10)\n",
      "\t[ -tc <k> ]\t\tNumber of threshold candidates to search. -1 to use all feature values (default=10)\n",
      "\n",
      "    [-] AdaRank-specific parameters\n",
      "\t[ -round <T> ]\t\tThe number of rounds to train (default=10)\n",
      "\t[ -noeq ]\t\tTrain without enqueuing too-strong features (default=unspecified)\n",
      "\t[ -tolerance <t> ]\tTolerance between two consecutive rounds of learning (default=0.002)\n",
      "\t[ -max <times> ]\tThe maximum number of times a feature can be consecutively selected without changing performance (default=5)\n",
      "\n",
      "    [-] Coordinate Ascent-specific parameters\n",
      "\t[ -r <k> ]\t\tThe number of random restarts (default=5)\n",
      "\t[ -i <iteration> ]\tThe number of iterations to search in each dimension (default=25)\n",
      "\t[ -tolerance <t> ]\tPerformance tolerance between two solutions (default=0.001)\n",
      "\t[ -reg <slack> ]\tRegularization parameter (default=no-regularization)\n",
      "\n",
      "    [-] {MART, LambdaMART}-specific parameters\n",
      "\t[ -tree <t> ]\t\tNumber of trees (default=1)\n",
      "\t[ -leaf <l> ]\t\tNumber of leaves for each tree (default=100)\n",
      "\t[ -shrinkage <factor> ]\tShrinkage, or learning rate (default=0.1)\n",
      "\t[ -tc <k> ]\t\tNumber of threshold candidates for tree spliting. -1 to use all feature values (default=256)\n",
      "\t[ -mls <n> ]\t\tMin leaf support -- minimum % of docs each leaf has to contain (default=1)\n",
      "\t[ -estop <e> ]\t\tStop early when no improvement is observed on validaton data in e consecutive rounds (default=-1)\n",
      "\n",
      "    [-] ListNet-specific parameters\n",
      "\t[ -epoch <T> ]\t\tThe number of epochs to train (default=10)\n",
      "\t[ -lr <rate> ]\t\tLearning rate (default=0.00001)\n",
      "\n",
      "    [-] Random Forests-specific parameters\n",
      "\t[ -bag <r> ]\t\tNumber of bags (default=10)\n",
      "\t[ -srate <r> ]\t\tSub-sampling rate (default=1.0)\n",
      "\t[ -frate <r> ]\t\tFeature sampling rate (default=1.0)\n",
      "\t[ -rtype <type> ]\tRanker to bag (default=0, i.e. MART)\n",
      "\t[ -tree <t> ]\t\tNumber of trees in each bag (default=1)\n",
      "\t[ -leaf <l> ]\t\tNumber of leaves for each tree (default=100)\n",
      "\t[ -shrinkage <factor> ]\tShrinkage, or learning rate (default=0.1)\n",
      "\t[ -tc <k> ]\t\tNumber of threshold candidates for tree spliting. -1 to use all feature values (default=256)\n",
      "\t[ -mls <n> ]\t\tMin leaf support -- minimum % of docs each leaf has to contain (default=1)\n",
      "\n",
      "    [-] Linear Regression-specific parameters\n",
      "\t[ -L2 <reg> ]\t\tL2 regularization parameter (default=1.0E-10)\n",
      "\n",
      "  [+] Testing previously saved models\n",
      "\t-load <model>\t\tThe model to load\n",
      "\t\t\t\tMultiple -load can be used to specify models from multiple folds (in increasing order),\n",
      "\t\t\t\t  in which case the test/rank data will be partitioned accordingly.\n",
      "\t-test <file>\t\tTest data to evaluate the model(s) (specify either this or -rank but not both)\n",
      "\t-rank <file>\t\tRank the samples in the specified file (specify either this or -test but not both)\n",
      "\t[ -metric2T <metric> ]\tMetric to evaluate on the test data (default=ERR@10)\n",
      "\t[ -gmax <label> ]\tHighest judged relevance label. It affects the calculation of ERR (default=4, i.e. 5-point scale {0,1,2,3,4})\n",
      "\t[ -score <file>]\tStore ranker's score for each object being ranked (has to be used with -rank)\n",
      "\t[ -qrel <file> ]\tTREC-style relevance judgment file. It only affects MAP and NDCG (default=unspecified)\n",
      "\t[ -idv <file> ]\t\tSave model performance (in test metric) on individual ranked lists (has to be used with -test)\n",
      "\t[ -norm ]\t\tNormalize feature vectors (similar to -norm for training/tuning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ranker: 6\n",
      "\n",
      "Discard orig. features\n",
      "Training data:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib692519236583645309tmp\n",
      "Feature vector representation: Dense.\n",
      "Ranking method:\tLambdaMART\n",
      "Feature description file:\tUnspecified. All features will be used.\n",
      "Train metric:\tmap\n",
      "Test metric:\tmap\n",
      "Feature normalization: No\n",
      "Model file: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib5992859941490874005tmp\n",
      "\n",
      "[+] LambdaMART's Parameters:\n",
      "No. of trees: 1\n",
      "No. of leaves: 100\n",
      "No. of threshold candidates: 256\n",
      "Min leaf support: 1\n",
      "Learning rate: 0.1\n",
      "Stop early: -1 rounds without performance gain on validation data\n",
      "\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib692519236583645309tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Initializing... [Done]\n",
      "---------------------------------\n",
      "Training starts...\n",
      "---------------------------------\n",
      "#iter   | MAP-T     | MAP-V     | \n",
      "---------------------------------\n",
      "1       | 1.0       | \n",
      "---------------------------------\n",
      "Finished sucessfully.\n",
      "MAP on training data: 1.0\n",
      "---------------------------------\n",
      "\n",
      "Model saved to: /var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib5992859941490874005tmp\n",
      "\n",
      "Discard orig. features\n",
      "Model file:\t/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib5992859941490874005tmp\n",
      "Feature normalization: No\n",
      "Model:\t\tLambdaMART\n",
      "Reading feature file [/var/folders/zx/6p0tyww13rn7xbr8p28vpdbm0000gn/T/ranklib692519236583645309tmp]... [Done.]            \n",
      "(1 ranked lists, 200 entries read)\n",
      "Tests run: 12, Failures: 0, Errors: 0, Skipped: 4, Time elapsed: 2.122 sec\n",
      "\n",
      "Results :\n",
      "\n",
      "Tests run: 13, Failures: 0, Errors: 0, Skipped: 4\n",
      "\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-jar-plugin:2.4:jar\u001b[m \u001b[1m(default-jar)\u001b[m @ \u001b[36mRankLib\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Building jar: /Users/leo/Downloads/test/FlexNeuART/lemur-code-r2792-RankLib-trunk/target/RankLib-2.14.jar\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1;32mBUILD SUCCESS\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Total time:  6.141 s\n",
      "[\u001b[1;34mINFO\u001b[m] Finished at: 2021-02-04T02:11:53-05:00\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "All is installed!\n"
     ]
    }
   ],
   "source": [
    "!./install_packages.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      " BUILDING main codebase \n",
      " log: /Users/leo/Downloads/test/FlexNeuART/main.build.log\n",
      "=======================\n",
      "BUILD IS COMPLETE!\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "!./build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-04 02:12:20--  http://boytsov.info/datasets/flecsneurt-demo-2020-04-07.tar.bz2\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44021208 (42M) [application/x-bzip2]\n",
      "Saving to: ‘flecsneurt-demo-2020-04-07.tar.bz2’\n",
      "\n",
      "flecsneurt-demo-202 100%[===================>]  41.98M  13.4MB/s    in 3.7s    \n",
      "\n",
      "2021-02-04 02:12:24 (11.5 MB/s) - ‘flecsneurt-demo-2020-04-07.tar.bz2’ saved [44021208/44021208]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/datasets/flecsneurt-demo-2020-04-07.tar.bz2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x collections/squad/derived_data/\n",
      "x collections/squad/derived_data/embeddings/\n",
      "x collections/squad/derived_data/bitext/\n",
      "x collections/squad/derived_data/bitext/question_text\n",
      "x collections/squad/derived_data/bitext/answer_text_unlemm\n",
      "x collections/squad/derived_data/bitext/question_text_unlemm\n",
      "x collections/squad/derived_data/bitext/answer_text\n",
      "x collections/squad/derived_data/embeddings/starspace/\n",
      "x collections/squad/derived_data/embeddings/starspace/starspace_unlemm.answer\n",
      "x collections/squad/derived_data/embeddings/starspace/dim=100_squad_emb_unlemm_epoch1.answer\n",
      "x collections/squad/derived_data/embeddings/starspace/dim=100_squad_emb_unlemm_epoch1.query\n",
      "x collections/squad/derived_data/embeddings/starspace/starspace_unlemm.query\n",
      "x collections/squad/forward_index/\n",
      "x collections/squad/input_data/\n",
      "x collections/squad/input_data/train_bitext/\n",
      "x collections/squad/input_data/dev1/\n",
      "x collections/squad/input_data/test/\n",
      "x collections/squad/input_data/dev2/\n",
      "x collections/squad/input_data/train/\n",
      "x collections/squad/input_data/train/AnswerFields.jsonl\n",
      "x collections/squad/input_data/train/QuestionFields.jsonl\n",
      "x collections/squad/input_data/train/qrels.txt\n",
      "x collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "x collections/squad/input_data/dev2/QuestionFields.jsonl\n",
      "x collections/squad/input_data/dev2/qrels.txt\n",
      "x collections/squad/input_data/test/AnswerFields.jsonl\n",
      "x collections/squad/input_data/test/QuestionFields.jsonl\n",
      "x collections/squad/input_data/test/qrels.txt\n",
      "x collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "x collections/squad/input_data/dev1/QuestionFields.jsonl\n",
      "x collections/squad/input_data/dev1/qrels.txt\n",
      "x collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "x collections/squad/input_data/train_bitext/QuestionFields.jsonl\n",
      "x collections/squad/input_data/train_bitext/qrels.txt\n",
      "x collections/squad/misc/\n",
      "x collections/squad/misc/cosine_fusion_dim=100_squad_emb_unlemm_epoch1.json\n",
      "x collections/squad/misc/out_squad_train_20.model\n",
      "x collections/squad/misc/bm25=text.json\n",
      "x collections/squad/misc/oneFeat.model\n"
     ]
    }
   ],
   "source": [
    "# Unpacking it\n",
    "!tar jxvf flecsneurt-demo-2020-04-07.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory: collections/squad/input_data\n",
      "Index directory: collections/squad/lucene_index\n",
      "==========================================================================\n",
      "Checking data sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl\n",
      "Checking data sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl\n",
      "Checking data sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl\n",
      "Checking data sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl\n",
      "Checking data sub-directory: train_bitext\n",
      "Found indexable data file: train_bitext/AnswerFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "Found query file: train_bitext/QuestionFields.jsonl\n",
      "Using the data input file: AnswerFields.jsonl\n",
      "JAVA_OPTS=-Xms8388608k -Xmx14680064k -server\n",
      "Creating a new Lucene index, maximum # of docs to process: 2147483647\n",
      "Input file name: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "Indexed 539 docs\n",
      "Input file name: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "Indexed 1106 docs\n",
      "Input file name: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "Indexed 3173 docs\n",
      "Input file name: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "Indexed 4302 docs\n",
      "Input file name: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "Indexed 10000 docs\n",
      "Indexed 20000 docs\n",
      "Indexed 20963 docs\n"
     ]
    }
   ],
   "source": [
    "# Creating a Lucene index\n",
    "!scripts/index/create_lucene_index.sh squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory:            collections/squad/input_data\n",
      "Forward index directory:   collections/squad/forward_index/\n",
      "Clean old index?:          1\n",
      "Removing previously created index (if exists)\n",
      "Field list definition:     text:parsedText text_unlemm:raw\n",
      "==========================================================================\n",
      "Checking data sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl\n",
      "Checking data sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl\n",
      "Checking data sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl\n",
      "Checking data sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl\n",
      "Checking data sub-directory: train_bitext\n",
      "Found indexable data file: train_bitext/AnswerFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "Found query file: train_bitext/QuestionFields.jsonl\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: parsedText\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 20963, total number of words 1381723, average reduction due to keeping only unique words 1.278678\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text_unlemm'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: raw\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 20963, total number of words 0, average reduction due to keeping only unique words 0.000000\n"
     ]
    }
   ],
   "source": [
    "#!creating a forward index for two fields:\n",
    "# text is a parsed text field\n",
    "# text_raw is a raw text field that keeps the text as is\n",
    "# -clean removes all previous forward indices\n",
    "!scripts/index/create_fwd_index.sh squad mapdb  \\\n",
    "                               \"text:parsedText text_unlemm:raw\" \\\n",
    "                               -clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Java JAR to the class path\n",
    "configure_classpath('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager('collections/squad/forward_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, 'collections/squad/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1961,\n",
       " [CandidateEntry(doc_id='@4309', score=27.225019454956055),\n",
       "  CandidateEntry(doc_id='@4323', score=27.155115127563477),\n",
       "  CandidateEntry(doc_id='@2608', score=26.603111267089844),\n",
       "  CandidateEntry(doc_id='@4310', score=26.364826202392578),\n",
       "  CandidateEntry(doc_id='@4303', score=26.196977615356445),\n",
       "  CandidateEntry(doc_id='@4350', score=25.074060440063477),\n",
       "  CandidateEntry(doc_id='@4346', score=24.675006866455078),\n",
       "  CandidateEntry(doc_id='@4316', score=24.361064910888672),\n",
       "  CandidateEntry(doc_id='@4336', score=23.92790985107422),\n",
       "  CandidateEntry(doc_id='@4345', score=23.00181007385254),\n",
       "  CandidateEntry(doc_id='@4320', score=22.964710235595703),\n",
       "  CandidateEntry(doc_id='@2607', score=22.55484390258789),\n",
       "  CandidateEntry(doc_id='@4325', score=22.466575622558594),\n",
       "  CandidateEntry(doc_id='@4330', score=21.723785400390625),\n",
       "  CandidateEntry(doc_id='@4348', score=21.596769332885742),\n",
       "  CandidateEntry(doc_id='@4321', score=21.47646713256836),\n",
       "  CandidateEntry(doc_id='@4338', score=21.426464080810547),\n",
       "  CandidateEntry(doc_id='@4307', score=21.014934539794922),\n",
       "  CandidateEntry(doc_id='@2067', score=20.57712745666504),\n",
       "  CandidateEntry(doc_id='@4342', score=20.57712745666504)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(cand_prov, 20, \"university notre dame student run\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward index demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's play with a raw index that keeps ony unparsed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_indx = get_forward_index(resource_manager, 'text_unlemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the raw flag is set\n",
    "raw_indx.is_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'architecturally school catholic character atop main building gold dome golden statue virgin mary immediately main building facing copper statue christ arms upraised legend venite ad omnes main building basilica sacred heart immediately basilica grotto marian place prayer reflection replica grotto lourdes france virgin mary reputedly appeared saint bernadette soubirous 1858 end main drive direct line connects 3 statues gold dome simple modern stone statue mary'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_indx.get_doc_raw('@4302')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A parsed index has more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_indx = get_forward_index(resource_manager, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is_raw is False\n",
    "parsed_indx.is_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocEntryParsed(word_ids=[1, 470, 480, 549, 770, 848, 857, 867, 1143, 1193, 1291, 1514, 1562, 1597, 1897, 2210, 2425, 2513, 2579, 3171, 3207, 3357, 3806, 3899, 3960, 4056, 4334, 4790, 5881, 6258, 6274, 6629, 6645, 7051, 7557, 8066, 9139, 10063, 11826, 12878, 13240, 16221, 20752, 32578, 32579, 32580, 32581, 32582, 32583], word_qtys=[1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], word_id_seq=[10063, 1, 6274, 848, 8066, 1291, 1193, 6645, 9139, 3171, 11826, 1143, 4334, 1597, 1291, 1193, 2210, 3899, 11826, 2425, 3806, 32578, 857, 32579, 7051, 13240, 1291, 1193, 4790, 7557, 4056, 1597, 4790, 32580, 6258, 1897, 5881, 16221, 6629, 32580, 32581, 3207, 1143, 4334, 20752, 470, 2579, 32582, 32583, 12878, 1562, 1291, 3357, 867, 770, 2513, 549, 11826, 6645, 9139, 1514, 480, 3960, 11826, 4334], doc_len=65)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_indx.get_doc_parsed('@4302')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('architecturally', WordEntry(word_id=10063, word_freq=11))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract the first document word and its info\n",
    "parsed_indx.get_word_by_id(10063), parsed_indx.get_word_entry_by_id(10063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
