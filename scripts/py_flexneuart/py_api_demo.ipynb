{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the repo is cloned, all necessary packages are installed, including calling the script:\n",
    "\n",
    "```./install_packages.sh```\n",
    "\n",
    "and the code is compiled:\n",
    "\n",
    "```./build.sh```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing directory to the repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leo/SourceTreeGit/FlexNeuART.refact2021\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-25 16:30:58--  http://boytsov.info/datasets/flecsneurt-demo-2021-02-08.tar.bz2\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7511061 (7.2M) [application/x-bzip2]\n",
      "Saving to: ‘flecsneurt-demo-2021-02-08.tar.bz2’\n",
      "\n",
      "flecsneurt-demo-202 100%[===================>]   7.16M  2.40MB/s    in 3.0s    \n",
      "\n",
      "2021-06-25 16:31:01 (2.40 MB/s) - ‘flecsneurt-demo-2021-02-08.tar.bz2’ saved [7511061/7511061]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/datasets/flecsneurt-demo-2021-02-08.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x collections/squad/\n",
      "x collections/squad/exper_desc/\n",
      "x collections/squad/input_data/\n",
      "x collections/squad/input_data/train_bitext/\n",
      "x collections/squad/input_data/dev1/\n",
      "x collections/squad/input_data/test/\n",
      "x collections/squad/input_data/dev2/\n",
      "x collections/squad/input_data/train/\n",
      "x collections/squad/input_data/train/AnswerFields.jsonl\n",
      "x collections/squad/input_data/train/QuestionFields.jsonl\n",
      "x collections/squad/input_data/train/qrels.txt\n",
      "x collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "x collections/squad/input_data/dev2/QuestionFields.jsonl\n",
      "x collections/squad/input_data/dev2/qrels.txt\n",
      "x collections/squad/input_data/test/AnswerFields.jsonl\n",
      "x collections/squad/input_data/test/QuestionFields.jsonl\n",
      "x collections/squad/input_data/test/qrels.txt\n",
      "x collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "x collections/squad/input_data/dev1/QuestionFields.jsonl\n",
      "x collections/squad/input_data/dev1/qrels.txt\n",
      "x collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "x collections/squad/input_data/train_bitext/QuestionFields.jsonl\n",
      "x collections/squad/input_data/train_bitext/qrels.txt\n",
      "x collections/squad/exper_desc/exper_list.json\n",
      "x collections/squad/exper_desc/models/\n",
      "x collections/squad/exper_desc/extractors/\n",
      "x collections/squad/exper_desc/extractors/bm25=text+cosine=text.json\n",
      "x collections/squad/exper_desc/extractors/bm25=text.json\n",
      "x collections/squad/exper_desc/models/oneFeat.model\n"
     ]
    }
   ],
   "source": [
    "# Unpacking it\n",
    "!tar jxvf flecsneurt-demo-2021-02-08.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory:    collections/squad/input_data\n",
      "Index directory:   collections/squad/lucene_index\n",
      "Index field name:  text\n",
      "Exact match param: \n",
      "Removing previously created index (if exists)\n",
      "==========================================================================\n",
      "Checking input sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl\n",
      "Checking input sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl\n",
      "Checking input sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl\n",
      "Checking input sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl\n",
      "Checking input sub-directory: train_bitext\n",
      "Found indexable data file: train_bitext/AnswerFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "Found query file: train_bitext/QuestionFields.jsonl\n",
      "Using the data input file: AnswerFields.jsonl\n",
      "JAVA_OPTS=-Xms8388608k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Creating a new Lucene index, maximum # of docs to process: 2147483647 exact match? false\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Input file name: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 539 docs\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Input file name: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 1106 docs\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Input file name: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 3173 docs\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Input file name: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 4302 docs\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Input file name: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 10000 docs\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 20000 docs\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.LuceneIndexer - Indexed 20963 docs\n"
     ]
    }
   ],
   "source": [
    "# Creating a Lucene index\n",
    "!scripts/index/create_lucene_index.sh squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory:            collections/squad/input_data\n",
      "Forward index directory:   collections/squad/forward_index/\n",
      "Clean old index?:          1\n",
      "Removing previously created index (if exists)\n",
      "Field list definition:     text:parsedText text_unlemm:raw\n",
      "==========================================================================\n",
      "Checking input sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl\n",
      "Checking input sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl\n",
      "Checking input sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl\n",
      "Checking input sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl\n",
      "Checking input sub-directory: train_bitext\n",
      "Found indexable data file: train_bitext/AnswerFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "Found query file: train_bitext/QuestionFields.jsonl\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index backend type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index field type: parsedText\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 20963, total number of words 1381723, average reduction due to keeping only unique words 1.278678\n",
      "WARNING: The raw text type name is changed. Use the name 'textRaw' to avoid this warning.\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text_unlemm'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index backend type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index field type: textRaw\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 20963, total number of words 0, average reduction due to keeping only unique words 0.000000\n"
     ]
    }
   ],
   "source": [
    "#!creating a forward index for two fields:\n",
    "# text is a parsed text field\n",
    "# text_raw is a raw text field that keeps the text as is\n",
    "# -clean removes all previous forward indices\n",
    "!scripts/index/create_fwd_index.sh squad mapdb  \\\n",
    "                               \"text:parsedText text_unlemm:raw\" \\\n",
    "                               -clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Java JAR to the class path\n",
    "configure_classpath('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager('collections/squad/forward_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import QUESTION_FILE_JSON, QREL_FILE, DOCID_FIELD, TEXT_FIELD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, 'collections/squad/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TEXT = \"university notre dame student run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,\n",
       " [CandidateEntry(doc_id='@4309', score=12.375007629394531),\n",
       "  CandidateEntry(doc_id='@4323', score=12.343233108520508),\n",
       "  CandidateEntry(doc_id='@2608', score=12.092323303222656),\n",
       "  CandidateEntry(doc_id='@4310', score=11.984010696411133),\n",
       "  CandidateEntry(doc_id='@4303', score=11.907716751098633),\n",
       "  CandidateEntry(doc_id='@4350', score=11.397300720214844),\n",
       "  CandidateEntry(doc_id='@4346', score=11.215911865234375),\n",
       "  CandidateEntry(doc_id='@4316', score=11.073210716247559),\n",
       "  CandidateEntry(doc_id='@4336', score=10.876322746276855),\n",
       "  CandidateEntry(doc_id='@4345', score=10.455368041992188),\n",
       "  CandidateEntry(doc_id='@4320', score=10.438504219055176),\n",
       "  CandidateEntry(doc_id='@2607', score=10.252201080322266),\n",
       "  CandidateEntry(doc_id='@4325', score=10.212079048156738),\n",
       "  CandidateEntry(doc_id='@4330', score=9.874446868896484),\n",
       "  CandidateEntry(doc_id='@4348', score=9.816712379455566),\n",
       "  CandidateEntry(doc_id='@4321', score=9.762029647827148),\n",
       "  CandidateEntry(doc_id='@4338', score=9.739300727844238),\n",
       "  CandidateEntry(doc_id='@4307', score=9.552242279052734),\n",
       "  CandidateEntry(doc_id='@2067', score=9.353239059448242),\n",
       "  CandidateEntry(doc_id='@4342', score=9.353239059448242)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a text query\n",
    "query_res = run_text_query(cand_prov, 20, QUERY_TEXT)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,\n",
       " [CandidateEntry(doc_id='@4309', score=12.375007629394531),\n",
       "  CandidateEntry(doc_id='@4323', score=12.343233108520508),\n",
       "  CandidateEntry(doc_id='@2608', score=12.092323303222656),\n",
       "  CandidateEntry(doc_id='@4310', score=11.984010696411133),\n",
       "  CandidateEntry(doc_id='@4303', score=11.907716751098633),\n",
       "  CandidateEntry(doc_id='@4350', score=11.397300720214844),\n",
       "  CandidateEntry(doc_id='@4346', score=11.215911865234375),\n",
       "  CandidateEntry(doc_id='@4316', score=11.073210716247559),\n",
       "  CandidateEntry(doc_id='@4336', score=10.876322746276855),\n",
       "  CandidateEntry(doc_id='@4345', score=10.455368041992188),\n",
       "  CandidateEntry(doc_id='@4320', score=10.438504219055176),\n",
       "  CandidateEntry(doc_id='@2607', score=10.252201080322266),\n",
       "  CandidateEntry(doc_id='@4325', score=10.212079048156738),\n",
       "  CandidateEntry(doc_id='@4330', score=9.874446868896484),\n",
       "  CandidateEntry(doc_id='@4348', score=9.816712379455566),\n",
       "  CandidateEntry(doc_id='@4321', score=9.762029647827148),\n",
       "  CandidateEntry(doc_id='@4338', score=9.739300727844238),\n",
       "  CandidateEntry(doc_id='@4307', score=9.552242279052734),\n",
       "  CandidateEntry(doc_id='@2067', score=9.353239059448242),\n",
       "  CandidateEntry(doc_id='@4342', score=9.353239059448242)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a generic query interface\n",
    "query_res = run_query(cand_prov, 20, {TEXT_FIELD_NAME : QUERY_TEXT}, default_query_id=FAKE_QUERY_ID)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,\n",
       " [CandidateEntry(doc_id='@4309', score=12.375007629394531),\n",
       "  CandidateEntry(doc_id='@4323', score=12.343233108520508),\n",
       "  CandidateEntry(doc_id='@2608', score=12.092323303222656),\n",
       "  CandidateEntry(doc_id='@4310', score=11.984010696411133),\n",
       "  CandidateEntry(doc_id='@4303', score=11.907716751098633),\n",
       "  CandidateEntry(doc_id='@4350', score=11.397300720214844),\n",
       "  CandidateEntry(doc_id='@4346', score=11.215911865234375),\n",
       "  CandidateEntry(doc_id='@4316', score=11.073210716247559),\n",
       "  CandidateEntry(doc_id='@4336', score=10.876322746276855),\n",
       "  CandidateEntry(doc_id='@4345', score=10.455368041992188),\n",
       "  CandidateEntry(doc_id='@4320', score=10.438504219055176),\n",
       "  CandidateEntry(doc_id='@2607', score=10.252201080322266),\n",
       "  CandidateEntry(doc_id='@4325', score=10.212079048156738),\n",
       "  CandidateEntry(doc_id='@4330', score=9.874446868896484),\n",
       "  CandidateEntry(doc_id='@4348', score=9.816712379455566),\n",
       "  CandidateEntry(doc_id='@4321', score=9.762029647827148),\n",
       "  CandidateEntry(doc_id='@4338', score=9.739300727844238),\n",
       "  CandidateEntry(doc_id='@4307', score=9.552242279052734),\n",
       "  CandidateEntry(doc_id='@2067', score=9.353239059448242),\n",
       "  CandidateEntry(doc_id='@4342', score=9.353239059448242)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a generic query interface\n",
    "query_res = run_query(cand_prov, 20, {DOCID_FIELD: FAKE_QUERY_ID, TEXT_FIELD_NAME : QUERY_TEXT})\n",
    "query_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward index demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's play with a raw index that keeps ony unparsed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_indx = get_forward_index(resource_manager, 'text_unlemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'textRaw'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index type\n",
    "raw_indx.indx_fld_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'architecturally school catholic character atop main building gold dome golden statue virgin mary immediately main building facing copper statue christ arms upraised legend venite ad omnes main building basilica sacred heart immediately basilica grotto marian place prayer reflection replica grotto lourdes france virgin mary reputedly appeared saint bernadette soubirous 1858 end main drive direct line connects 3 statues gold dome simple modern stone statue mary'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_indx.get_doc_text_raw('@4302')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A parsed index has more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_indx = get_forward_index(resource_manager, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parsedText'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index type\n",
    "parsed_indx.indx_fld_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocEntryParsed(word_ids=[1, 470, 480, 549, 770, 848, 857, 867, 1143, 1193, 1291, 1514, 1562, 1597, 1897, 2210, 2425, 2513, 2579, 3171, 3207, 3357, 3806, 3899, 3960, 4056, 4334, 4790, 5881, 6258, 6274, 6629, 6645, 7051, 7557, 8066, 9139, 10063, 11826, 12878, 13240, 16221, 20752, 32578, 32579, 32580, 32581, 32582, 32583], word_qtys=[1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], word_id_seq=[10063, 1, 6274, 848, 8066, 1291, 1193, 6645, 9139, 3171, 11826, 1143, 4334, 1597, 1291, 1193, 2210, 3899, 11826, 2425, 3806, 32578, 857, 32579, 7051, 13240, 1291, 1193, 4790, 7557, 4056, 1597, 4790, 32580, 6258, 1897, 5881, 16221, 6629, 32580, 32581, 3207, 1143, 4334, 20752, 470, 2579, 32582, 32583, 12878, 1562, 1291, 3357, 867, 770, 2513, 549, 11826, 6645, 9139, 1514, 480, 3960, 11826, 4334], doc_len=65)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_indx.get_doc_parsed('@4302')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('architecturally', WordEntry(word_id=10063, word_freq=11))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract the first document word and its info\n",
    "parsed_indx.get_word_by_id(10063), parsed_indx.get_word_entry_by_id(10063)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker API demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we run two experiments that involve training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete old results if they are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf collections/squad/results/dev1/feat_exper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Running two experiments (you can add ``-no_separate_shell`` to print logs to the screen for debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "The number of CPU cores:      8\n",
      "The number of || experiments: 1\n",
      "The number of threads:        8\n",
      "================================================================================\n",
      "Experiment descriptor file:                                 collections/squad/exper_desc/exper_list.json\n",
      "Default test set:                                           dev1\n",
      "Number of parallel experiments:                             1\n",
      "Number of threads in feature extractors/query applications: 8\n",
      "================================================================================\n",
      "Parsed experiment parameters:\n",
      "experSubdir:feat_exper/bm25=text\n",
      "extrType:exper_desc/extractors/bm25=text.json\n",
      "testOnly:0\n",
      "========================================\n",
      "Started a process 17182, working dir: collections/squad/results/dev1/feat_exper/bm25=text\n",
      "Process log file: collections/squad/results/dev1/feat_exper/bm25=text/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=17182 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:feat_exper/bm25=text+cosine=text\n",
      "extrType:exper_desc/extractors/bm25=text+cosine=text.json\n",
      "testOnly:0\n",
      "========================================\n",
      "Started a process 17248, working dir: collections/squad/results/dev1/feat_exper/bm25=text+cosine=text\n",
      "Process log file: collections/squad/results/dev1/feat_exper/bm25=text+cosine=text/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=17248 finished successfully.\n",
      "Waiting for 0 child processes\n",
      "================================================================================\n",
      "2 experiments executed\n",
      "0 experiments failed\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!scripts/exper/run_experiments.sh squad \\\n",
    "    exper_desc/exper_list.json \\\n",
    "    -train_part train \\\n",
    "    -test_part dev1 \\\n",
    "    -test_cand_qty_list 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results generated by ``trec_eval``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of queries:    2448\r\n",
      "NDCG@10:  0.925700\r\n",
      "NDCG@20:  0.927800\r\n",
      "NDCG@100: 0.929900\r\n",
      "P20:      0.048600\r\n",
      "MAP:      0.914100\r\n",
      "MRR:      0.914100\r\n",
      "Recall:   0.983660\r\n"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/results/dev1/feat_exper/bm25\\=text+cosine\\=text/rep/out_100.rep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, we can use this model to re-rank and evaluate results using Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.ranker import *\n",
    "from scripts.py_flexneuart.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE_NAME='collections/squad/results/dev1/feat_exper/bm25=text+cosine=text/letor/out_squad_train_20.model'\n",
    "FEAT_EXTR_FILE_NAME='collections/squad/exper_desc/extractors/bm25=text+cosine=text.json'\n",
    "QUERY_FILE_NAME=f'collections/squad/input_data/dev1/{QUESTION_FILE_JSON}'\n",
    "QREL_FILE_NAME=f'collections/squad/input_data/dev1/{QREL_FILE}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list of experimental descriptors, which in turn reference descriptors for feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"experSubdir\": \"feat_exper/bm25=text\",\r\n",
      "    \"extrType\" : \"exper_desc/extractors/bm25=text.json\",\r\n",
      "    \"testOnly\": 0\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"experSubdir\": \"feat_exper/bm25=text+cosine=text\",\r\n",
      "    \"extrType\" : \"exper_desc/extractors/bm25=text+cosine=text.json\",\r\n",
      "    \"testOnly\": 0\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/exper_desc/exper_list.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A (two-feature) feature extractor confguration, which is used in the second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"extractors\" : [\r\n",
      " {\r\n",
      "  \"type\" : \"TFIDFSimilarity\",\r\n",
      "  \"params\" : {\r\n",
      "    \"indexFieldName\" : \"text\",\r\n",
      "    \"similType\" : \"bm25\",\r\n",
      "    \"k1\"        : \"1.2\",\r\n",
      "    \"b\"         : \"0.75\"\r\n",
      "  }\r\n",
      " },\r\n",
      " {\r\n",
      "  \"type\" : \"TFIDFSimilarity\",\r\n",
      "  \"params\" : {\r\n",
      "    \"indexFieldName\" : \"text\",\r\n",
      "    \"similType\" : \"cosine\"\r\n",
      "  }\r\n",
      " }\r\n",
      "]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/exper_desc/extractors/bm25=text+cosine=text.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple linear model trained to combine feature scores produced by the feature-extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Coordinate Ascent\r\n",
      "## Restart = 10\r\n",
      "## MaxIteration = 50\r\n",
      "## StepBase = 0.05\r\n",
      "## StepScale = 2.0\r\n",
      "## Tolerance = 0.001\r\n",
      "## Regularized = false\r\n",
      "## Slack = 0.001\r\n",
      "1:0.5464353855587661 2:-0.4535646144412339"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/results/dev1/feat_exper/bm25=text+cosine=text/letor/out_squad_train_20.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we generate a list of candidates for merely one query (using the candidate provider) and re-rank them using the Java-layer re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_ranker = JavaQueryRanker(resource_manager, feat_extr_file_name=FEAT_EXTR_FILE_NAME, model_file_name=MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@4323', 0.5067933451547831),\n",
       " ('@4303', 0.48961460832303094),\n",
       " ('@4309', 0.47475528548967094),\n",
       " ('@2608', 0.4549869297008977),\n",
       " ('@4346', 0.4413701458990109),\n",
       " ('@4316', 0.4355512672038647),\n",
       " ('@4310', 0.4332624225820959),\n",
       " ('@4320', 0.4277601854466731),\n",
       " ('@2067', 0.4229184488598747),\n",
       " ('@4342', 0.4052451627386573),\n",
       " ('@4307', 0.39438917386601124),\n",
       " ('@4336', 0.3835355648995015),\n",
       " ('@4321', 0.37744164995227447),\n",
       " ('@4350', 0.36827643790295006),\n",
       " ('@4325', 0.3681315865508774),\n",
       " ('@4330', 0.3626696414510794),\n",
       " ('@2607', 0.3619121883629782),\n",
       " ('@4345', 0.3617851826918027),\n",
       " ('@4348', 0.3596303010435613),\n",
       " ('@4338', 0.3456784985640041)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              TEXT_FIELD_NAME : QUERY_TEXT}\n",
    "java_ranker.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There's a function (used only for evaluation) to score candidates without sorting them scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@4309': 0.47475528548967094,\n",
       " '@4323': 0.5067933451547831,\n",
       " '@2608': 0.4549869297008977,\n",
       " '@4310': 0.4332624225820959,\n",
       " '@4303': 0.48961460832303094,\n",
       " '@4350': 0.36827643790295006,\n",
       " '@4346': 0.4413701458990109,\n",
       " '@4316': 0.4355512672038647,\n",
       " '@4336': 0.3835355648995015,\n",
       " '@4345': 0.3617851826918027,\n",
       " '@4320': 0.4277601854466731,\n",
       " '@2607': 0.3619121883629782,\n",
       " '@4325': 0.3681315865508774,\n",
       " '@4330': 0.3626696414510794,\n",
       " '@4348': 0.3596303010435613,\n",
       " '@4321': 0.37744164995227447,\n",
       " '@4338': 0.3456784985640041,\n",
       " '@4307': 0.39438917386601124,\n",
       " '@2067': 0.4229184488598747,\n",
       " '@4342': 0.4052451627386573}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_ranker.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we re-rank the list of candidate using a BERT re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-25 16:36:28--  http://boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 438863972 (419M) [text/plain]\n",
      "Saving to: ‘model.best’\n",
      "\n",
      "model.best          100%[===================>] 418.53M  11.0MB/s    in 50s     \n",
      "\n",
      "2021-06-25 16:37:18 (8.43 MB/s) - ‘model.best’ saved [438863972/438863972]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/anaconda3/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/leo/anaconda3/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/leo/anaconda3/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/leo/anaconda3/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/leo/anaconda3/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Re-ranking on CPU, which can be fairly slow\n",
    "cedr_ranker = PythonNNQueryRanker(resource_manager, \n",
    "                         query_field_name='text_unlemm', max_query_len=32,\n",
    "                         index_field_name='text_unlemm', max_doc_len = 512 - 32 - 3,\n",
    "                         device_name='cpu', batch_size=4, model_file_name='model.best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@4303', 3.6410412788391113),\n",
       " ('@4316', 2.2296292781829834),\n",
       " ('@4309', 1.0998224020004272),\n",
       " ('@4310', 0.9482794404029846),\n",
       " ('@4338', 0.8910526037216187),\n",
       " ('@4330', 0.7861899137496948),\n",
       " ('@4323', 0.5350112915039062),\n",
       " ('@2608', 0.5348656177520752),\n",
       " ('@4336', 0.28653576970100403),\n",
       " ('@4348', 0.19181787967681885),\n",
       " ('@4325', 0.1362343430519104),\n",
       " ('@2607', 0.13104315102100372),\n",
       " ('@4342', 0.08876024186611176),\n",
       " ('@4307', 0.07658989727497101),\n",
       " ('@4350', 0.029552193358540535),\n",
       " ('@2067', -0.24131406843662262),\n",
       " ('@4320', -0.3115100860595703),\n",
       " ('@4345', -0.3343726396560669),\n",
       " ('@4346', -0.45976755023002625),\n",
       " ('@4321', -0.4623507857322693)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              'text_unlemm' : QUERY_TEXT}\n",
    "cedr_ranker.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A comprehensive example where we evaluate **all** queries from `dev1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_convert.convert_common import *\n",
    "all_queries = read_queries(QUERY_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DOCNO': '10595',\n",
       "  'text_unlemm': 'beyonce lighter skin color costuming',\n",
       "  'text': 'beyonce lighter skin color costume'},\n",
       " {'DOCNO': '10608',\n",
       "  'text_unlemm': 'exclusion social political groups targets genocide cppcg legal',\n",
       "  'text': 'exclusion social political group target genocide cppcg legal'},\n",
       " {'DOCNO': '10575',\n",
       "  'text_unlemm': 'beyonce giselle knowles-carter',\n",
       "  'text': 'beyonce giselle knowles-carter'},\n",
       " {'DOCNO': '10570',\n",
       "  'text_unlemm': 'school architecture',\n",
       "  'text': 'school architecture'},\n",
       " {'DOCNO': '10576',\n",
       "  'text_unlemm': 'bee-yon-say born september 4 1981 american',\n",
       "  'text': 'bee-yon-say bear september 4 1981 american'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query sample\n",
    "all_queries[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2448/2448 [00:17<00:00, 136.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "TOP_K=100\n",
    "\n",
    "run_dict = {}\n",
    "for query_dict in tqdm(all_queries):\n",
    "    qid = query_dict[DOCID_FIELD]\n",
    "    query_res = run_text_query(cand_prov, TOP_K, query_dict[TEXT_FIELD_NAME])\n",
    "    rank_res = java_ranker.score_candidates(query_res[1], query_dict)\n",
    "    run_dict[qid] = rank_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, let us compute various metrics using our Python code. Note that results should match results previously produced by `trec_eval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \r"
     ]
    }
   ],
   "source": [
    "from scripts.eval_common import *\n",
    "qrels=read_qrels_dict(QREL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9236950321010553\n",
      "0.9258372608440565\n",
      "0.9120987070833969\n",
      "0.9120987070833969\n"
     ]
    }
   ],
   "source": [
    "for eval_obj in [NormalizedDiscountedCumulativeGain(10), \\\n",
    "                 NormalizedDiscountedCumulativeGain(20), \\\n",
    "                 MeanAveragePrecision(), \\\n",
    "                 MeanReciprocalRank()]:\n",
    "    print(eval_run(rerank_run=run_dict, metric_func=eval_obj, qrels_dict=qrels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionally we can save the run to be later evaluated using external evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_run_dict(run_dict, 'run.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10595 Q0 @2069 1 0.5034178698142255 fake_run\r\n",
      "10595 Q0 @17442 2 0.19901719649322208 fake_run\r\n",
      "10595 Q0 @9111 3 0.19225397364078217 fake_run\r\n",
      "10595 Q0 @1769 4 0.19119073815505058 fake_run\r\n",
      "10595 Q0 @2228 5 0.19033063864976146 fake_run\r\n",
      "10595 Q0 @8585 6 0.18989114401672533 fake_run\r\n",
      "10595 Q0 @18222 7 0.18815638945124924 fake_run\r\n",
      "10595 Q0 @9121 8 0.1853920865272263 fake_run\r\n",
      "10595 Q0 @18223 9 0.18299288131025784 fake_run\r\n",
      "10595 Q0 @9120 10 0.1778561648387402 fake_run\r\n"
     ]
    }
   ],
   "source": [
    "!head run.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
