{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation/processing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to move to the top-level directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leo/SourceTreeGit/FlexNeuART.refact2021\n"
     ]
    }
   ],
   "source": [
    "cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example covers a Manner subset of the Yahoo Answers Comprehensive.\n",
    "However, a similar procedure can be applied to a bigger collection. All\n",
    "experiments assume the variable `COLLECT_ROOT` in the script `scripts/config.sh` \n",
    "is set to `collections` and that all collections are stored in the `collections`\n",
    "sub-directory (relative to the source code root).\n",
    "\n",
    "\n",
    "Create raw-data directory and store raw data there:\n",
    "```\n",
    "mkdir -p collections/manner/input_pre_raw\n",
    "\n",
    "cp <data path>/manner.xml.bz2 collections/manner/input_pre_raw/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner.xml.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!ls collections/manner/input_pre_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to split the data. The following command creates  several\n",
    "training and testing subsets, including a ``bitext`` subset that can\n",
    "be used to train either IBM Model 1 or a neural IR model. \n",
    "We would reserve a much smaller ``train`` data set to train\n",
    "a fusion/LETOR model that could combine several signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p collections/manner/input_raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using probabilities:\n",
      "dev1 : 0.05\n",
      "dev2 : 0.05\n",
      "test : 0.1\n",
      "train : 0.1\n",
      "bitext : 0.7\n",
      "=================================================\n",
      "Processed 1000 documents\n",
      "Processed 2000 documents\n",
      "Processed 3000 documents\n",
      "Processed 4000 documents\n",
      "Processed 5000 documents\n",
      "Processed 6000 documents\n",
      "Processed 7000 documents\n",
      "Processed 8000 documents\n",
      "Processed 9000 documents\n",
      "Processed 10000 documents\n",
      "Processed 11000 documents\n",
      "Processed 12000 documents\n",
      "Processed 13000 documents\n",
      "Processed 14000 documents\n",
      "Processed 15000 documents\n",
      "Processed 16000 documents\n",
      "Processed 17000 documents\n",
      "Processed 18000 documents\n",
      "Processed 19000 documents\n",
      "Processed 20000 documents\n",
      "Processed 21000 documents\n",
      "Processed 22000 documents\n",
      "Processed 23000 documents\n",
      "Processed 24000 documents\n",
      "Processed 25000 documents\n",
      "Processed 26000 documents\n",
      "Processed 27000 documents\n",
      "Processed 28000 documents\n",
      "Processed 29000 documents\n",
      "Processed 30000 documents\n",
      "Processed 31000 documents\n",
      "Processed 32000 documents\n",
      "Processed 33000 documents\n",
      "Processed 34000 documents\n",
      "Processed 35000 documents\n",
      "Processed 36000 documents\n",
      "Processed 37000 documents\n",
      "Processed 38000 documents\n",
      "Processed 39000 documents\n",
      "Processed 40000 documents\n",
      "Processed 41000 documents\n",
      "Processed 42000 documents\n",
      "Processed 43000 documents\n",
      "Processed 44000 documents\n",
      "Processed 45000 documents\n",
      "Processed 46000 documents\n",
      "Processed 47000 documents\n",
      "Processed 48000 documents\n",
      "Processed 49000 documents\n",
      "Processed 50000 documents\n",
      "Processed 51000 documents\n",
      "Processed 52000 documents\n",
      "Processed 53000 documents\n",
      "Processed 54000 documents\n",
      "Processed 55000 documents\n",
      "Processed 56000 documents\n",
      "Processed 57000 documents\n",
      "Processed 58000 documents\n",
      "Processed 59000 documents\n",
      "Processed 60000 documents\n",
      "Processed 61000 documents\n",
      "Processed 62000 documents\n",
      "Processed 63000 documents\n",
      "Processed 64000 documents\n",
      "Processed 65000 documents\n",
      "Processed 66000 documents\n",
      "Processed 67000 documents\n",
      "Processed 68000 documents\n",
      "Processed 69000 documents\n",
      "Processed 70000 documents\n",
      "Processed 71000 documents\n",
      "Processed 72000 documents\n",
      "Processed 73000 documents\n",
      "Processed 74000 documents\n",
      "Processed 75000 documents\n",
      "Processed 76000 documents\n",
      "Processed 77000 documents\n",
      "Processed 78000 documents\n",
      "Processed 79000 documents\n",
      "Processed 80000 documents\n",
      "Processed 81000 documents\n",
      "Processed 82000 documents\n",
      "Processed 83000 documents\n",
      "Processed 84000 documents\n",
      "Processed 85000 documents\n",
      "Processed 86000 documents\n",
      "Processed 87000 documents\n",
      "Processed 88000 documents\n",
      "Processed 89000 documents\n",
      "Processed 90000 documents\n",
      "Processed 91000 documents\n",
      "Processed 92000 documents\n",
      "Processed 93000 documents\n",
      "Processed 94000 documents\n",
      "Processed 95000 documents\n",
      "Processed 96000 documents\n",
      "Processed 97000 documents\n",
      "Processed 98000 documents\n",
      "Processed 99000 documents\n",
      "Processed 100000 documents\n",
      "Processed 101000 documents\n",
      "Processed 102000 documents\n",
      "Processed 103000 documents\n",
      "Processed 104000 documents\n",
      "Processed 105000 documents\n",
      "Processed 106000 documents\n",
      "Processed 107000 documents\n",
      "Processed 108000 documents\n",
      "Processed 109000 documents\n",
      "Processed 110000 documents\n",
      "Processed 111000 documents\n",
      "Processed 112000 documents\n",
      "Processed 113000 documents\n",
      "Processed 114000 documents\n",
      "Processed 115000 documents\n",
      "Processed 116000 documents\n",
      "Processed 117000 documents\n",
      "Processed 118000 documents\n",
      "Processed 119000 documents\n",
      "Processed 120000 documents\n",
      "Processed 121000 documents\n",
      "Processed 122000 documents\n",
      "Processed 123000 documents\n",
      "Processed 124000 documents\n",
      "Processed 125000 documents\n",
      "Processed 126000 documents\n",
      "Processed 127000 documents\n",
      "Processed 128000 documents\n",
      "Processed 129000 documents\n",
      "Processed 130000 documents\n",
      "Processed 131000 documents\n",
      "Processed 132000 documents\n",
      "Processed 133000 documents\n",
      "Processed 134000 documents\n",
      "Processed 135000 documents\n",
      "Processed 136000 documents\n",
      "Processed 137000 documents\n",
      "Processed 138000 documents\n",
      "Processed 139000 documents\n",
      "Processed 140000 documents\n",
      "Processed 141000 documents\n",
      "Processed 142000 documents\n",
      "Processed 142627 documents\n"
     ]
    }
   ],
   "source": [
    "!scripts/data_convert/yahoo_answers/split_yahoo_answers_input.sh \\\n",
    "  -i collections/manner/input_pre_raw/manner.xml.bz2  \\\n",
    "  -o collections/manner/input_raw/manner-v2.0 \\\n",
    "  -n dev1,dev2,test,train,bitext \\\n",
    "  -p 0.05,0.05,0.1,0.1,0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create input data in the JSONL format. Note that the last argument defines a \n",
    "part of the collection that is used to create a parallel corpus (i.e,\n",
    "a bitext), which is generated in addition to JSONL input files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/data_convert/yahoo_answers/convert_yahoo_answers.sh \\\n",
    "  manner \\\n",
    "  dev1,dev2,test,train,bitext \\\n",
    "  bitext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "As a basic sanity check, it is recommended to run the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Checking data sub-directory: bitext\n",
      "Found indexable data file: bitext/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl.gz\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "getIndexQueryDataInfo return value:  bitext,dev1,dev2,test,train AnswerFields.jsonl.gz ,bitext,dev1,dev2,test,train QuestionFields.jsonl\n",
      "Using the data input files: AnswerFields.jsonl.gz, QuestionFields.jsonl\n",
      "Index dirs: bitext dev1 dev2 test train\n",
      "Query dirs:  bitext dev1 dev2 test train\n",
      "Queries/questions:\n",
      "bitext 99950\n",
      "dev1 7034\n",
      "dev2 7150\n",
      "test 14214\n",
      "train 14279\n",
      "Documents/passages/answers:\n",
      "bitext 572790\n",
      "dev1 40497\n",
      "dev2 41603\n",
      "test 80847\n",
      "train 83868\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_basic_collect_stat.sh manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a more thorough check, we would like to ensure that the split collection\n",
    "does not have data leaks, i.e., similar question-answer pairs shared among different splits.\n",
    "It is most crucial to check for overlaps between parts ``dev1`` (``dev2``, ``test``) and ``bitext``:\n",
    "as well as between any testing subset and ``train``. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n",
      "Namespace(data_dir='collections/manner/input_data/', input_subdir1='dev1', input_subdir2='bitext', k=1, min_jacc=0.75, sample_prob1=1.0, sample_prob2=1.0, use_hnsw=False)\n",
      "Read 7034 queries from collections/manner/input_data/dev1/QuestionFields.jsonl sampled 7034\n",
      "Read 99950 queries from collections/manner/input_data/bitext/QuestionFields.jsonl sampled 99950\n",
      "Read 7034 qrel sets from collections/manner/input_data/dev1/qrels.txt\n",
      "Read 99950 qrel sets from collections/manner/input_data/bitext/qrels.txt\n",
      "loading answers: 40497it [00:00, 42570.85it/s]\n",
      "Read 40497 answers from collections/manner/input_data/dev1/AnswerFields.jsonl.gz\n",
      "loading answers: 572790it [00:13, 42713.65it/s]\n",
      "Read 572790 answers from collections/manner/input_data/bitext/AnswerFields.jsonl.gz\n",
      "k-NN search method brute_force\n",
      "reading query set to build a k-NN search index: 100%|█| 3124/3124 [01:36<00:00, \n",
      "# of data points to index 99950\n",
      "Index-time parameters {}\n",
      "Indexing time = 0.000086\n",
      "Setting query-time parameters {}\n",
      "K= 1\n",
      "query w/ 1st query set: 100%|█████████████████| 220/220 [01:26<00:00,  2.54it/s]\n",
      "Maximum similarity among questions: 1.0\n",
      "Distribution of question-neighbor *SIMILARITIES* for k=1\n",
      " quant| simil\n",
      "------+------\n",
      "  0.2  | 0.28571\n",
      "  0.3  | 0.31081\n",
      "  0.4  | 0.33333\n",
      "  0.5  | 0.375\n",
      "  0.6  | 0.41667\n",
      "  0.7  | 0.46667\n",
      "  0.8  | 0.53333\n",
      "  0.9  | 0.63636\n",
      " 0.91  | 0.64286\n",
      " 0.92  | 0.66667\n",
      " 0.93  | 0.6875\n",
      " 0.94  | 0.70029\n",
      " 0.95  | 0.75\n",
      " 0.96  | 0.77778\n",
      " 0.97  | 0.84615\n",
      " 0.98  | 1\n",
      " 0.99  | 1\n",
      "0.999  | 1\n",
      "0.999  | 1\n",
      "Distribution of relevant answer pairwise *SIMILARITIES* from neighbor questions with Jaccard >= 0.75\n",
      " quant| simil\n",
      "------+------\n",
      "  0.2  | 0.016393\n",
      "  0.3  | 0.030303\n",
      "  0.4  | 0.043478\n",
      "  0.5  | 0.057143\n",
      "  0.6  | 0.071429\n",
      "  0.7  | 0.085714\n",
      "  0.8  | 0.10185\n",
      "  0.9  | 0.12636\n",
      " 0.91  | 0.12963\n",
      " 0.92  | 0.13333\n",
      " 0.93  | 0.13684\n",
      " 0.94  | 0.14141\n",
      " 0.95  | 0.14655\n",
      " 0.96  | 0.15217\n",
      " 0.97  | 0.15966\n",
      " 0.98  | 0.16923\n",
      " 0.99  | 0.18411\n",
      "0.999  | 0.23748\n",
      "0.999  | 0.23748\n",
      "Check is successful!\n"
     ]
    }
   ],
   "source": [
    "!./scripts/check_utils/check_split_leak.py \\\n",
    "  --data_dir collections/manner/input_data/ \\\n",
    "  --input_subdir1 dev1 \\\n",
    "  --input_subdir2 bitext \\\n",
    "  -k 1  --min_jacc 0.75 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "Lucene index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/index/create_lucene_index.sh manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a forward index. There are several types of the index with different \n",
    "space/efficiency/tradeoffs:\n",
    "1. `mapdb` is the fastest, but not the smallest and not the most memory efficient index. Its size may also be limited by the number of `mmap` ranges permited by your OS. \n",
    "2. `flatdata` requires less memory at index time, but it is somewhat slower at re-ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/index/create_fwd_index.sh \\\n",
    "  manner \\\n",
    "  mapdb \\\n",
    "  'text:parsedBOW text_unlemm:parsedText text_bert_tok:parsedText text_raw:raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line defines a type of the index for each indexed field. \n",
    "At a high level, there are two types of the field: a parsed text field and a raw field.\n",
    "The raw text field keeps text \"as is\". A parsed field processor white-space tokenizes the text and compiles token statistics.\n",
    "More specifically:\n",
    "1. `parsedBOW` index keeps only a bag of words;\n",
    "2. `parsedText` keeps the original word sequence;\n",
    "3. `raw` is the index that stores text \"as is\" without any changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating & using optional (derived) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an IBM Model 1 model\n",
    "\n",
    "Here we create a model for the field `text_bert_tok`. This script requires MGIZA to be compiled (make sure you ran the script `install_packages.sh`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/giza/create_tran.sh manner text_bert_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It further needs to cleaned-up and converted to a binary format (infrequent tokens need to be filtered out as well). \n",
    "Note that for BERT-tokenized text, which has less than\n",
    "100K unique tokens, the maximum number of most frequent words\n",
    "is too high. However, it makes sense for, e.g.,\n",
    "unlemmatized text fields with large vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!min_tran_prob=0.001 ; top_word_qty=1000000 ; echo $min_tran_prob ; top_word_qty=100000 ; \\\n",
    "scripts/giza/filter_tran_table_and_voc.sh \\\n",
    "    manner \\\n",
    "    text_bert_tok \\\n",
    "    $min_tran_prob \\\n",
    "    $top_word_qty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CEDR neural ranking models\n",
    "\n",
    "Training requires exporting data in the format of the \n",
    "CEDR framework ([MacAvaney et al' 2019](https://github.com/Georgetown-IR-Lab/cedr)).\n",
    "The following command\n",
    "generates training data in the CEDR format for the collection `manner`\n",
    "and the field `text_raw`. The traing data is generated from the split `bitext`, \n",
    "whereas split `dev1` is used to generate validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "========================================================\n",
      "Train split: bitext\n",
      "Eval split: dev1\n",
      "Random seed: 0\n",
      "Output directory: collections/manner/derived_data/cedr_train/text_raw\n",
      "# of threads: 4\n",
      "Index field: text_raw\n",
      "Query field: text_raw\n",
      "Candidate provider parameters:  -cand_prov \"lucene\" -u \"collections/manner/lucene_index\" \n",
      "Resource parameters: -fwd_index_dir \"collections/manner/forward_index/\" -embed_dir \"collections/manner/derived_data/embeddings/\" -giza_root_dir \"collections/manner/derived_data/giza\" \n",
      "A # of hard/medium/easy samples per query: 0/20/0\n",
      "A max. # of candidate records to generate training data: 500\n",
      "A max. # of candidate records to generate test data: 10\n",
      "Max train query # param.: \n",
      "Max test/dev query # param.: \n",
      "Case handling param: \n",
      "========================================================\n",
      "JAVA_OPTS=-Xms16469316k -Xmx28821303k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainPairs - Candidate provider type: lucene URI: collections/manner/lucene_index config: null\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainPairs - Number of threads: 4\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.cand_providers.CandidateProvider - Provider type: lucene URI: collections/manner/lucene_index config file: none # of threads\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Lucene candidate provider k1=1.20000, b=0.750000\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainPairs - Ignoring query with empty field 'text' for query '4083'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainPairs - Ignoring query with empty field 'text' for query '2588'\n",
      "Finished loading context from file: collections/manner/forward_index//text_raw.mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainNegSampleBase - # of hard/medium/easy samples per query: 0/20/0\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.utils.RandomUtils - New random generator with seed: 0\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainNegSampleBase - Lower-casing? true\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainNegSampleBase - # top-scoring training candidates to sample/select from 500\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainNegSampleBase - # top candidates for validation 10\n",
      "[Thread-5] WARN edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainCEDR - Ignoring document 75132-6 b/c of empty field\n",
      "[Thread-3] WARN edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainCEDR - Ignoring document 124836-0 b/c of empty field\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.ExportTrainCEDR - Generated data for 106982 queries 760905 documents 2640130 training query-doc pairs\n"
     ]
    }
   ],
   "source": [
    "!scripts/export_train/export_cedr.sh \\\n",
    "  manner \\\n",
    "  text_raw \\\n",
    "  bitext \\\n",
    "  dev1 \\\n",
    "  -thread_qty 4 \\\n",
    "  -hard_neg_qty 0 \\\n",
    "  -sample_easy_neg_qty 0 \\\n",
    "  -sample_med_neg_qty 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we can use a wrapper convenience script that reads most parameters from a configuration file. First it needs to be copied to a collection directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp scripts/exper/sample_model_conf/manner/bert_vanilla_manner.json collections/manner/exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the following ``train_model.sh`` scripts assumes that the training data path is **relative** to the ``derived_data`` subdirectory while other paths are **relative** to the collection root. The training script has a number of options (check them out by running with the option ``-h``). Here is how one can run a training script (remember this requires a GPU and pytorch with CUDA support):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/cedr/train_model.sh manner cedr_train/text_raw vanilla_bert -json_conf exper_desc/bert_vanilla_manner.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scripts runs, both training and evaluation. The respective statistics is stored in a JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"0\": {\r\n",
      "        \"loss\": 0.2031547787311188,\r\n",
      "        \"score\": 0.1208771612093101,\r\n",
      "        \"lr\": 0.0002,\r\n",
      "        \"bert_lr\": 2e-05,\r\n",
      "        \"train_time\": 7956.939112901688,\r\n",
      "        \"validation_time\": 688.1996886730194\r\n",
      "    }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat collections/manner/derived_data/ir_models/vanilla_bert/base/0/train_stat.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be readily compared to the BM25 score **using the same query subset** by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\tfake_run\r\n",
      "num_q                 \tall\t7033\r\n",
      "num_ret               \tall\t70312\r\n",
      "num_rel               \tall\t40489\r\n",
      "num_rel_ret           \tall\t4273\r\n",
      "map                   \tall\t0.0982\r\n",
      "gm_map                \tall\t0.0004\r\n",
      "Rprec                 \tall\t0.1018\r\n",
      "bpref                 \tall\t0.1512\r\n",
      "recip_rank            \tall\t0.2535\r\n",
      "iprec_at_recall_0.00  \tall\t0.2565\r\n",
      "iprec_at_recall_0.10  \tall\t0.2278\r\n",
      "iprec_at_recall_0.20  \tall\t0.1782\r\n",
      "iprec_at_recall_0.30  \tall\t0.1320\r\n",
      "iprec_at_recall_0.40  \tall\t0.0989\r\n",
      "iprec_at_recall_0.50  \tall\t0.0896\r\n",
      "iprec_at_recall_0.60  \tall\t0.0468\r\n",
      "iprec_at_recall_0.70  \tall\t0.0439\r\n",
      "iprec_at_recall_0.80  \tall\t0.0349\r\n",
      "iprec_at_recall_0.90  \tall\t0.0340\r\n",
      "iprec_at_recall_1.00  \tall\t0.0340\r\n",
      "P_5                   \tall\t0.0924\r\n",
      "P_10                  \tall\t0.0608\r\n",
      "P_15                  \tall\t0.0405\r\n",
      "P_20                  \tall\t0.0304\r\n",
      "P_30                  \tall\t0.0203\r\n",
      "P_100                 \tall\t0.0061\r\n",
      "P_200                 \tall\t0.0030\r\n",
      "P_500                 \tall\t0.0012\r\n",
      "P_1000                \tall\t0.0006\r\n"
     ]
    }
   ],
   "source": [
    "!trec_eval/trec_eval collections/manner/derived_data/cedr_train/text_raw/qrels.txt collections/manner/derived_data/cedr_train/text_raw/test_run.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that BM25 has the mean average precision (MAP) of ``0.0982``, which is about **23% worse compared to the BERT model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running basic experiments\n",
    "\n",
    "First let us create a directory to store experiment descriptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p collections/manner/exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning BM25\n",
    "A tuning procedure simply executes a number of descriptor files\n",
    "with various BM25 parameters. To create descriptors one runs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(exper_subdir='tuning', index_field_name='text', outdir='collections/manner/exper_desc/', query_field_name='text', rel_desc_path='exper_desc')\r\n"
     ]
    }
   ],
   "source": [
    "!scripts/gen_exper_desc/gen_bm25_tune_json_desc.py \\\n",
    "  --index_field_name text \\\n",
    "  --query_field_name text \\\n",
    "  --outdir collections/manner/exper_desc/ \\\n",
    "  --exper_subdir tuning \\\n",
    "  --rel_desc_path exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main experimental descriptor is going to be stored in  `collections/manner/exper_desc/bm25tune.json`,\n",
    "whereas auxiliary descriptors are stored in `collections/manner/exper_desc/bm25tune/`\n",
    "\n",
    "Now we can run tuning experiments where we train on `train` and test on `dev1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "The number of CPU cores:      8\n",
      "The number of || experiments: 1\n",
      "The number of threads:        8\n",
      "================================================================================\n",
      "Experiment descriptor file:                                 collections/manner/exper_desc/bm25tune_text_text.json\n",
      "Default test set:                                           dev1\n",
      "Number of parallel experiments:                             1\n",
      "Number of threads in feature extractors/query applications: 8\n",
      "================================================================================\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 20972, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=20972 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21061, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21061 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21146, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21146 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21234, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21234 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21323, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21323 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21407, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21407 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.3\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.3.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21491, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.3\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.3/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21491 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21581, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21581 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21665, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21665 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21750, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21750 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21834, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21834 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 21923, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=21923 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22007, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22007 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.4\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.4.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22091, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.4\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.4/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22091 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22177, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process with pid=22177 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22265, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22265 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22350, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22350 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22434, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22434 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22518, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22518 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22607, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22607 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.5\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.5.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22692, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.5\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.5/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22692 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22796, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22796 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22885, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22885 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 22970, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=22970 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23054, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23054 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23139, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23139 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23228, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23228 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.6\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.6.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23315, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.6\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.6/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23315 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23401, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23401 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23485, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23485 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23573, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23573 finished successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23658, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23658 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23743, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23743 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23828, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23828 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.7\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.7.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 23916, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.7\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.7/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=23916 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24001, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24001 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24086, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24086 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24172, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24172 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24272, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24272 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24356, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24356 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24442, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24442 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.8\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.8.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24526, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.8\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.8/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24526 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24615, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24615 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24700, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24700 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24784, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24784 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24893, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24893 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 24977, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=24977 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started a process 25063, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25063 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.9\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=0.9.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25147, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.9\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=0.9/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25147 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.4_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.4_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25235, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.4_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25235 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.6_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.6_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25323, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.6_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25323 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=0.8_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=0.8_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25408, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=0.8_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25408 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25493, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25493 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.2_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.2_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25582, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.2_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25582 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.4_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.4_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25666, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.4_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25666 finished successfully.\n",
      "Parsed experiment parameters:\n",
      "experSubdir:tuning/bm25tune_text_text/bm25tune_k1=1.6_b=1\n",
      "extrType:exper_desc/bm25tune_text_text/bm25tune_k1=1.6_b=1.json\n",
      "testOnly:1\n",
      "modelFinal:exper_desc/models/one_feat.model\n",
      "Started a process 25751, working dir: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=1\n",
      "Process log file: collections/manner/results/dev1/tuning/bm25tune_text_text/bm25tune_k1=1.6_b=1/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=25751 finished successfully.\n",
      "Waiting for 0 child processes\n",
      "================================================================================\n",
      "56 experiments executed\n",
      "0 experiments failed\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!scripts/exper/run_experiments.sh \\\n",
    "  manner \\\n",
    "  exper_desc/bm25tune_text_text.json \\\n",
    "  -test_part dev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, experiments are run in the background: In fact, there\n",
    "can be more than one experiment run. However, for debugging purposes,\n",
    "one can run experiments in the foreground by specifying the\n",
    "option `-no_separate_shell`.\n",
    "\n",
    "Furthermore, the script `scripts/exper/run_experiments.sh` has a number of parameters,\n",
    "which might be worth tweaking.\n",
    "In particular, for \"shallow\" relevance pools, one\n",
    "can use default number of candidates (which is small).\n",
    "However, for queries with a lot of relevance judgments,\n",
    "it makes sense to slightly increase the number of top candidate\n",
    "entries that are used to obtain a fusion model \n",
    "(parameter ``-train_cand_qty``).\n",
    "\n",
    "Now, let us obtain experimental results and find the best configuration \n",
    "with respect to the Mean Average Precision (MAP), which should be nearly equal to ``0.1165``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Including only runs that generated 250 candidate records\n",
      "Best results for metric map:\n",
      "Value: 0.116500\n",
      "Result sub-dir: tuning/bm25tune_text_text/bm25tune_k1=0.4_b=0.7\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_exper_results.sh \\\n",
    "  manner \\\n",
    "  exper_desc/bm25tune_text_text.json \\\n",
    "  bm25tune.tsv \\\n",
    "  -test_part dev1 \\\n",
    "  -flt_cand_qty 250 \\\n",
    "  -print_best_metr map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning a fusion of IBM Model 1 and BM25\n",
    "\n",
    "IBM Model 1 has quite a few parameters and can benefit from tuning as well.\n",
    "Rather than tuning IBM Model 1 alone, we tune its fusion with the BM25 score for the field\n",
    "`text`. Here we use optimal BM25 coefficients __obtained in the previous experiment__.\n",
    "Model 1 descriptors are going to be created for the field `text_bert_tok`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b=0.7, exper_subdir='feat_exper', index_field_name='text_bert_tok', k1=0.4, outdir='collections/manner/exper_desc/', query_field_name='text_bert_tok', rel_desc_path='exper_desc')\r\n"
     ]
    }
   ],
   "source": [
    "!scripts/gen_exper_desc/gen_model1_exper_json_desc.py \\\n",
    "  -k1 0.4 -b 0.7  \\\n",
    "  --query_field_name text_bert_tok \\\n",
    "  --index_field_name text_bert_tok \\\n",
    "  --outdir collections/manner/exper_desc/ \\\n",
    "  --rel_desc_path exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run tuning experiments where we train on `train` and test on `dev1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh \\\n",
    "  manner \\\n",
    "  exper_desc/model1tune_text_bert_tok_text_bert_tok.json \\\n",
    "  -test_part dev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the best configuration with respect to MAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Including only runs that generated 250 candidate records\n",
      "Best results for metric map:\n",
      "Value: 0.137500\n",
      "Result sub-dir: feat_exper/model1tune_text_bert_tok_text_bert_tok/bm25=text+model1=text_bert_tok+lambda=0.3+probSelfTran=0.15\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_exper_results.sh \\\n",
    "  manner \\\n",
    "  exper_desc/model1tune_text_bert_tok_text_bert_tok.json \\\n",
    "  model1_text_bert_tok_tune.tsv \\\n",
    "  -test_part dev1 \\\n",
    "  -flt_cand_qty 250 \\\n",
    "  -print_best_metr map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning RM3\n",
    "\n",
    "RM3 component is a pseudo-relevance feedback via re-ranking.\n",
    "The whole process is quite similar to BM25 tuning descriptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b=0.7, exper_subdir='tuning', index_field_name='text', k1=0.4, outdir='collections/manner/exper_desc/', query_field_name='text', rel_desc_path='exper_desc')\r\n"
     ]
    }
   ],
   "source": [
    "!scripts/gen_exper_desc/gen_rm3_exper_json_desc.py \\\n",
    "  -k1 0.4 -b 0.7  \\\n",
    "  --index_field_name text \\\n",
    "  --query_field_name text \\\n",
    "  --outdir collections/manner/exper_desc/ \\\n",
    "  --exper_subdir tuning \\\n",
    "  --rel_desc_path exper_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run tuning experiments where we train on `train` and test on `dev1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/exper/run_experiments.sh \\\n",
    "  manner \\\n",
    "  exper_desc/rm3tune_text_text.json \\\n",
    "  -test_part dev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the best configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Including only runs that generated 250 candidate records\n",
      "Best results for metric map:\n",
      "Value: 0.115600\n",
      "Result sub-dir: tuning/rm3tune_text_text/rm3=text+text_origWeight=0.9_topDocQty=1_topTermQty=2_k1=0.4_0.7\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_exper_results.sh \\\n",
    "  manner \\\n",
    "  exper_desc/rm3tune_text_text.json \\\n",
    "  bm25tune.tsv \\\n",
    "  -test_part dev1 \\\n",
    "  -flt_cand_qty 250 \\\n",
    "  -print_best_metr map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
