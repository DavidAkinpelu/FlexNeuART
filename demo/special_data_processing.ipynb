{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two things to do before we start:\n",
    "1. Point environment variable `COLLECT_ROOT` to the collection root.\n",
    "2. Change directory to the location of installed scripts/binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: COLLECT_ROOT=/home/leo/flexneuart_collections\n"
     ]
    }
   ],
   "source": [
    "%env COLLECT_ROOT=/home/leo/flexneuart_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leo/flexneuart_scripts\n"
     ]
    }
   ],
   "source": [
    "cd /home/leo/flexneuart_scripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA data: weak supervision with answer-based QRELs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of QA the set of relevance passages is obtained by retrieving a top-K set of passages using a candidate provider and checking if the passages contain an answer as a substring. Facebook Wikipedia DPR data is shipped with relevance information obtain in such as a way. However, not all collections are. Furthermore, this data depends a lot on the quality of a candidate generator. Ideally, when multiple retrieval systems are used and comapred, the sets of  relevance documents (from their respective top-k sets) need to be combined (i.e., **pooled**). Our framework does support such a functionality. To this end, each query entry in a JSONL file needs to have special field \"answer_list\", e.g.:\n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    "    \"DOCNO\": \"dev_official_0\",\n",
    "    \"text\": \"sing love reba\",\n",
    "    \"text_raw\": \"who sings does he love me with reba\",\n",
    "    \"answer_list\": [\n",
    "        \"Linda Davis\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Then the respective set of QRELs can be generated using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: /home/leo/flexneuart_collections\n",
      "==========================================================================\n",
      "Collection directory:      /home/leo/flexneuart_collections/wikipedia_dpr_nq_sample\n",
      "Data directory:            /home/leo/flexneuart_collections/wikipedia_dpr_nq_sample/input_data/bitext\n",
      "Output file:               /home/leo/flexneuart_collections/wikipedia_dpr_nq_sample/qrels_generated_from_bitext_queries.txt\n",
      "Candidate provider options: -u lucene_index/ \n",
      "# of candidate documents:  1000\n",
      "Field name:                text_raw\n",
      "Forward index directory:   forward_index/\n",
      "Query file name prefix:    /home/leo/flexneuart_collections/wikipedia_dpr_nq_sample/input_data/bitext/QuestionFields\n",
      "# of threads:              8\n",
      "==========================================================================\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.AnswerBasedQRELGenerator - Candidate provider type: lucene URI: lucene_index/ config: null\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.AnswerBasedQRELGenerator - Number of threads: 8\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.resources.ResourceManager - Resource manager initialization. Resource root:/home/leo/flexneuart_collections/wikipedia_dpr_nq_sample\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.MapDbBackend - MapDB opened for reading: /home/leo/flexneuart_collections/wikipedia_dpr_nq_sample/forward_index/text_raw.mapdb_dataDict\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndexBinaryDataDict - Finished loading context from file: /home/leo/flexneuart_collections/wikipedia_dpr_nq_sample/forward_index/text_raw.mapdb_dataDict\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.resources.ResourceManager - Provider type: lucene\n",
      "URI: lucene_index/\n",
      "Config file: none\n",
      "# of threads: 8\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Lucene candidate provider k1=1.20000, b=0.750000 query field name: text index field name: text Exact field match?: false\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.AnswerBasedQRELGenerator - Finished loading queries!\n",
      "[Thread-9] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 1279\n",
      "[Thread-8] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 1390\n",
      "[Thread-7] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 3157\n",
      "[Thread-5] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 4691\n",
      "[Thread-8] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 13414\n",
      "[Thread-8] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 21190\n",
      "[Thread-3] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 30873\n",
      "[Thread-2] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 33336\n",
      "[Thread-9] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 33943\n",
      "[Thread-3] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 37961\n",
      "[Thread-9] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 49231\n",
      "[Thread-3] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 49873\n",
      "[Thread-2] WARN edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Ignoring empty query #: 53608\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.AnswerBasedQRELGenerator - Processed 53880 queries\n"
     ]
    }
   ],
   "source": [
    "!data_convert/create_answ_based_qrels.sh  \\\n",
    "    wikipedia_dpr_nq_sample \\\n",
    "    bitext \\\n",
    "    text_raw \\\n",
    "    qrels_generated_from_bitext_queries.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating parallel corpus (bitext) without explicitly paired data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of queries paired with a set of short relevant passages can be used to train a lexical IBM Model 1 model whose fusion with BM25 can be quite effective as a ranking model. In the case of QA data, such as corpus can be easily created by pairing questions with sentences containing an answer. This is what we do when we process the Wikipedia DPR corpus. However, such pairing generally does not exist for more generic ad hoc retrieval collections. It can still be possible to create a reasonable quality paired data by splitting a relevant passage into multiple short chunks and pairing each chunk with the respective queries. This works especially well for short passages or short information snippets such as titles, urls, or headings.\n",
    "\n",
    "Here is an example of creating such an artificial bitext corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./giza/export_bitext_plain.sh \\\n",
    "    wikipedia_dpr_nq_sample \\\n",
    "    text_bert_tok text_bert_tok \\\n",
    "    2 \\\n",
    "    -bitext_out_subdir bitext_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train the Model 1 model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./giza/create_tran.sh wikipedia_dpr_nq_sample text_bert_tok \\\n",
    "   -bitext_subdir bitext_generated \\\n",
    "   -model1_subdir giza_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to prune the translation table and store it in a special format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!min_tran_prob=0.001 ; top_word_qty=1000000 ; echo $min_tran_prob ; top_word_qty=100000 ; \\\n",
    "./giza/filter_tran_table_and_voc.sh \\\n",
    "    wikipedia_dpr_nq_sample \\\n",
    "    text_bert_tok \\\n",
    "    $min_tran_prob \\\n",
    "    $top_word_qty \\\n",
    "    -model1_subdir giza_generated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
